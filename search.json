[{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"risk-prediction-models","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models","what":"Risk prediction models","title":"Introduction to the CalibrationCurves package","text":"package, focus risk prediction models estimate probability \\(\\pi_i\\) observing event. use \\(y_i \\(0, 1)\\) denote variable captures outcome takes value 0 case non-event 1 case event. , \\(\\) serves index observations (mostly patient within medical predictive analytics) \\(= (1, \\dots, n)\\) \\(n\\) denotes total number observations. assume response variable \\(y_i\\) follows Bernoulli distribution \\(y_i \\sim \\text{Bern}(\\pi_i)\\). example, interested estimating probability \\(\\pi_i\\) observing malignant tumour patient \\(\\). case, event \\(y_i = 1\\) tumour malignant \\(y_i = 0\\) tumour benign. available information patient characteristics, might rely prevalence general population estimate probability. Using risk prediction models, model outcome function observed risk/patient characteristics. risk characteristics contained covariate vector \\(\\boldsymbol{x}_i\\). vector contains observed information patient \\(\\) (e.g. maximum diameter lesion, proportion solid tissue, …). allows us obtain accurate prediction based relation patient characteristics outcome. construct clinical prediction model, either rely statistical models logistic regression machine learning methods. general expression encompasses types models \\[\\begin{align*} E[y_i | \\boldsymbol{x}_i] = f(\\boldsymbol{x}_i). \\end{align*}\\] expression states model response \\(y_i\\) function observed risk characteristics \\(\\boldsymbol{x}_i\\).","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"mathematical-details-on-existing-predictive-models","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models > 1.1 Risk prediction models","what":"Mathematical details on existing predictive models","title":"Introduction to the CalibrationCurves package","text":"construct risk prediction model, rely logistic regression model. general equation type model \\[\\begin{align*} E[y_i | \\boldsymbol{x}_i] = \\pi_i(\\boldsymbol{\\beta}) = \\frac{e^{\\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}}}{1 + e^{\\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}}} \\end{align*}\\] \\(\\boldsymbol{\\beta}\\) denotes parameter vector. \\(\\pi_i(\\boldsymbol{\\beta}) = P(y_i = 1| \\boldsymbol{x}_i)\\) denotes probability observing event, given covariate vector \\(\\boldsymbol{x}_i\\). can rewrite equation well-known form \\[\\begin{align*} \\log\\left( \\frac{\\pi_i(\\boldsymbol{\\beta})}{1 - \\pi_i(\\boldsymbol{\\beta})} \\right) &= \\boldsymbol{x}_i^\\top \\boldsymbol{\\beta}\\\\[0.5em] \\text{logit}(\\pi_i(\\boldsymbol{\\beta})) &= \\eta_i. \\end{align*}\\] , well-known logit function left side equation. machine learning methods, \\(f(\\cdot)\\) depends specific algorithm. tree-based methods, example, correspond observed proportion leaf nodes. neural networks, \\(f(\\cdot)\\) determined weights layers chosen activation functions.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"different-aspects-of-the-predictive-performance","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models","what":"Different aspects of the predictive performance","title":"Introduction to the CalibrationCurves package","text":"assess well model able predict (probability ) outcome, assess two different aspects model (Van Calster et al. 2016, 2019; Alba et al. 2017): discrimination; calibration. discrimination, refer model’s ability differentiate observations event observations . context, translates giving higher risk estimates patients event patients without event. commonly assess using area receiver operating characteristic curve. However, discrimination performance tell us accurate predictions . estimated risk may result good discrimination can inaccurate time. refer accuracy predictions calibration. Hence, hereby assess agreement estimated observed number events (Van Calster et al. 2016). say prediction model calibrated predicted risks correspond observations proportions event.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"how-do-we-assess-calibration-performance","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models","what":"How do we assess calibration performance?","title":"Introduction to the CalibrationCurves package","text":"One way examine calibration risk predictions, using calibration curves. calibration curve visualizes correspondence model’s predicted risks observed proportion. perfect agreement observed predicted proportion calibration curve coincides ideal curve (diagonal line). scenario visualized Figure 1.1. Figure 1.1: Example perfectly calibrated model therefore assess calibration performance predictive model data set training set. Hereby, obtain indication well risk prediction able generalize data sets accurate --sample predictions . general, prediction model show miscalibration calibration curve gives us visual depiction badly model miscalibrated. diagonal line, worse calibration. Figure 1.2 depicts example model miscalibrated typical example model overfitted training data. particular model predictions extreme: high risks overestimated low risks underestimated. Figure 1.2: Example miscalibrated model due overfitting counterpart, underfitted model, occurs less frequently. 1.3 shows calibration curve underfitted model. , overestimation low risks underestimation high risks. Figure 1.3: Example miscalibrated model due underfitting","code":""},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"training-the-model","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models > 1.4 Illustration of the CalibrationCurves package","what":"Training the model","title":"Introduction to the CalibrationCurves package","text":"illustrate functionality, package two example data sets: traindata testdata. two synthetically generated data sets (using underlying process/settings generate data) illustrate functionality CalibrationCurves package. traindata data frame represents data use develop risk prediction model data frame, four covariates one response variable y. Next, fit logistic regression model obtain estimated parameter vector \\(\\widehat{\\beta}\\).","code":"library(CalibrationCurves) #> Loading required package: rms #> Loading required package: Hmisc #>  #> Attaching package: 'Hmisc' #> The following objects are masked from 'package:base': #>  #>     format.pval, units #> Loading required package: survival #> Loading required package: lattice #> Loading required package: ggplot2 #> Loading required package: SparseM #>  #> Attaching package: 'SparseM' #> The following object is masked from 'package:base': #>  #>     backsolve data(\"traindata\") head(traindata) #>   y          x1         x2         x3         x4 #> 1 0 -0.19981624  0.2982990  1.0277486 -0.1146414 #> 2 1 -1.37127488  0.5940002 -0.8234645  2.0927676 #> 3 1  1.04050541  0.5440481 -1.3576457  1.3126813 #> 4 0 -1.11652476 -0.5382577 -1.1651439  1.0987873 #> 5 1  1.39659613  1.1325081  0.6053029 -1.0598506 #> 6 0 -0.04645095 -0.8167364  1.0196761 -0.4867560 glmFit = glm(y ~ . , data = traindata, family = binomial) summary(glmFit) #>  #> Call: #> glm(formula = y ~ ., family = binomial, data = traindata) #>  #> Deviance Residuals:  #>     Min       1Q   Median       3Q      Max   #> -2.5686  -0.7388   0.1474   0.7575   3.0008   #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  0.08915    0.08016   1.112    0.266     #> x1           0.60585    0.08475   7.148 8.79e-13 *** #> x2           1.38035    0.10554  13.079  < 2e-16 *** #> x3          -0.75109    0.08854  -8.483  < 2e-16 *** #> x4           0.82757    0.08759   9.448  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 1385.89  on 999  degrees of freedom #> Residual deviance:  950.28  on 995  degrees of freedom #> AIC: 960.28 #>  #> Number of Fisher Scoring iterations: 5"},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"assessing-the-calibration-performance","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models > 1.4 Illustration of the CalibrationCurves package","what":"Assessing the calibration performance","title":"Introduction to the CalibrationCurves package","text":"Hereafter, assess calibration performance testdata set. Hereto, first compute predicted probabilities data set. store response testdata separate vector yTest. Now everything need assess calibration performance prediction model. can either use val.prob.ci.2 valProbggplot visualize calibration performance obtain statistics. val.prob.ci.2 makes plot using base R valProbggplot uses ggplot2 package. default, flexible calibration curve (based loess smoother) plotted. addition plot, function returns object class CalibrationCurve. object contains calculated statistics well calculated coordinates calibration curve. coordinates stored CalibrationCurves slot can extracted follows.  Alternatively, can use restricted cubic splines obtain flexible calibration curve.  obtain logistic calibration curve using following code.  can plot using  package also allows change colors, change position legend much . Check help-function see arguments functions .  Finally, can also decide statistics appear plot.","code":"data(\"testdata\") pHat = predict(glmFit, newdata = testdata, type = \"response\") yTest = testdata$y calPerf = val.prob.ci.2(pHat, yTest) calPerf #> Call: #> val.prob.ci.2(p = pHat, y = yTest) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.62856683   0.81428341   0.38019823   0.33282644 167.41322219   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01286390   8.43195136   0.01475792   0.31996254   0.17703339   0.22404680  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.82278297   0.08288689   0.28730517   0.04747448   0.32064056 str(calPerf) #> List of 7 #>  $ call             : language val.prob.ci.2(p = pHat, y = yTest) #>  $ stats            : Named num [1:17] 0.629 0.814 0.38 0.333 167.413 ... #>   ..- attr(*, \"names\")= chr [1:17] \"Dxy\" \"C (ROC)\" \"R2\" \"D\" ... #>  $ cl.level         : num 0.95 #>  $ Calibration      :List of 2 #>   ..$ Intercept: Named num [1:3] 0.22405 0.00339 0.4447 #>   .. ..- attr(*, \"names\")= chr [1:3] \"Point estimate\" \"Lower confidence limit\" \"Upper confidence limit\" #>   ..$ Slope    : Named num [1:3] 0.823 0.666 0.98 #>   .. ..- attr(*, \"names\")= chr [1:3] \"Point estimate\" \"Lower confidence limit.2.5 %\" \"Upper confidence limit.97.5 %\" #>  $ Cindex           : Named num [1:3] 0.814 0.774 0.848 #>   ..- attr(*, \"names\")= chr [1:3] \"Point estimate\" \"Lower confidence limit\" \"Upper confidence limit\" #>  $ warningMessages  : NULL #>  $ CalibrationCurves:List of 1 #>   ..$ FlexibleCalibration:'data.frame':  500 obs. of  4 variables: #>   .. ..$ x   : num [1:500] 0.00561 0.00651 0.00706 0.01183 0.01235 ... #>   .. ..$ y   : num [1:500] 0.0504 0.0514 0.052 0.0572 0.0578 ... #>   .. ..$ ymin: num [1:500] 0 0 0 0 0 0 0 0 0 0 ... #>   .. ..$ ymax: num [1:500] 0.177 0.177 0.177 0.179 0.179 ... #>  - attr(*, \"class\")= chr \"CalibrationCurve\" flexCal = calPerf$CalibrationCurves$FlexibleCalibration plot(flexCal[, 1:2], type = \"l\", xlab = \"Predicted probability\", ylab = \"Observed proportion\", lwd = 2, xlim = 0:1, ylim = 0:1) polygon(   x = c(flexCal$x, rev(flexCal$x)),   y = c(     flexCal$ymax,     rev(flexCal$ymin)   ),   col = rgb(177, 177, 177, 177, maxColorValue = 255),   border = NA ) invisible(val.prob.ci.2(pHat, yTest, smooth = \"rcs\")) invisible(val.prob.ci.2(pHat, yTest, logistic.cal = TRUE, smooth = \"none\")) invisible(val.prob.ci.2(pHat, yTest, logistic.cal = TRUE, col.log = \"orange\")) invisible(val.prob.ci.2(pHat, yTest, col.ideal = \"black\", col.smooth = \"red\", CL.smooth = TRUE,               legendloc = c(0, 1), statloc = c(0.6, 0.25))) invisible(val.prob.ci.2(pHat, yTest, dostats = c(\"C (ROC)\", \"Intercept\", \"Slope\", \"ECI\")))"},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"ggplot-version","dir":"Articles","previous_headings":"1 Assessing the performance of risk prediction models > 1.4 Illustration of the CalibrationCurves package","what":"ggplot version","title":"Introduction to the CalibrationCurves package","text":"ggplot version (.e.valProbggplot) uses virtually arguments. Hence, can easily obtain ggplot using code.","code":"valProbggplot(pHat, yTest) #> Call: #> valProbggplot(p = pHat, y = yTest) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.62856683   0.81428341   0.38019823   0.33282644 167.41322219   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01286390   8.43195136   0.01475792   0.31996254   0.17703339   0.22404680  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.82278297   0.08288689   0.28730517   0.04747448   0.32064056"},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/articles/CalibrationCurves.html","id":"i-have-predicted-probabilities-of-0-or-1--why-is-this-not-allowed-by-default-and-why-do-i-get-these-annoying-warning-messages","dir":"Articles","previous_headings":"2 FAQ","what":"I have predicted probabilities of 0 or 1. Why is this not allowed by default and why do I get these annoying warning messages?","title":"Introduction to the CalibrationCurves package","text":"Predicted probabilities 0 1 imply randomness process deterministic. process truly deterministic, model . Mostly presence perfect predictions signifies something went wrong fitting model model severely overfitted. therefore make sure allowed default delete observations. observe behavior following cases:  - logistic regression: quasi-complete separation, coefficients tend infinity;  - tree-based methods: one leaf nodes contains observations either 0 1;  - neural networks: weights tend infinity known weight/gradient explosion. confident nothing wrong model fit, can obtain calibration curve setting argument allowPerfectPredictions TRUE. case, predictions 0 1 replaced values 1e-8 1 - 1e-8, respectively. take account interpreting performance measures, calculated original values.","code":"set.seed(1) pHat[sample(1:length(pHat), 5, FALSE)] = sample(0:1, 5, TRUE) x = val.prob.ci.2(pHat, yTest, allowPerfectPredictions = TRUE) #> Warning in val.prob.ci.2(pHat, yTest, allowPerfectPredictions = TRUE): There are predictions with value 0 or 1! These are replaced by values 1e-8 and 1 - 1e-8, respectively. Take this into account when interpreting the performance measures, as these are not calculated with the original values. #>  #> Please check your model, as this may be an indication of overfitting. Predictions of 0 or 1 imply that these predicted values are deterministic. #>  #> We observe this in the following cases: #>  - logistic regression: with quasi-complete separation, the coefficients tend to infinity; #>  - tree-based methods: one of the leaf nodes contains only observations with either 0 or 1; #>  - neural networks: the weights tend to infinity and this is known as weight/gradient explosion."},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"De Cock Bavo. Author, maintainer. Nieboer Daan. Author. Van Calster Ben. Author. Steyerberg Ewout. Author. Vergouwe Yvonne. Author.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina, M.J., Steyerberg, E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176. doi: 10.1016/j.jclinepi.2015.12.005. De Cock, B., Nieboer, D., Van Calster, B., Steyerberg, E.W., Vergouwe, Y. (2023). CalibrationCurves package: validating predicted probabilities binary events. R package version 1.0.1, https://cran.r-project.org/package=CalibrationCurves","code":"@Article{,   title = {A calibration hierarchy for risk models was defined: from utopia to empirical data},   author = {Ben {Van Calster} and Daan Nieboer and Yvonne Vergouwe and Bavo {De Cock} and Michael J. Pencina and Ewout W. Steyerberg},   journal = {Journal of Clinical Epidemiology},   year = {2016},   volume = {74},   pages = {167--176},   doi = {10.1016/j.jclinepi.2015.12.005}, } @Manual{,   title = {The CalibrationCurves package: validating predicted probabilities against binary events.},   author = {Bavo {De Cock} and Daan Nieboer and Ben {Van Calster} and Ewout W. Steyerberg and Yvonne Vergouwe},   year = {2023},   note = {R package version 1.0.1},   url = {https://cran.r-project.org/package=CalibrationCurves}, }"},{"path":"https://bavodc.github.io/CalibrationCurves/index.html","id":"calibrationcurves-validating-predicted-probabilities-against-binary-events","dir":"","previous_headings":"","what":"Calibration Performance","title":"Calibration Performance","text":"Package generate logistic flexible calibration curves related statistics. Based val.prob function Frank Harrell’s rms package.","code":""},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/index.html","id":"on-current-r--300","dir":"","previous_headings":"Installation","what":"On current R (>= 3.0.0)","title":"Calibration Performance","text":"Development version Github: (requires devtools >= 1.6.1, installs “master” (development) branch.) approach builds package source, .e. make compilers must installed system – see R FAQ operating system; may also need install dependencies manually.","code":"library(\"devtools\"); install_github(\"BavoDC/CalibrationCurves\", dependencies = TRUE)"},{"path":"https://bavodc.github.io/CalibrationCurves/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Calibration Performance","text":"basic functionality package explained demonstrated homepage package. currently working upgrade package, contain tutorial comprehensive documentation methods covered (well various improvements) package.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Calibration Performance","text":"questions, remarks suggestions regarding package, can contact bavo.decock@kuleuven.bavo.campo@kuleuven..","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Calibration Performance","text":"use package, please cite: De Cock, B., Nieboer, D., Van Calster, B., Steyerberg, E.W., Vergouwe, Y. (2023). CalibrationCurves package: validating predicted probabilities binary events. R package version 1.0.2, https://cran.r-project.org/package=CalibrationCurves Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina, M.J., Steyerberg, E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":null,"dir":"Reference","previous_headings":"","what":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"Obtain point estimate confidence interval   AUC various methods based Mann-Whitney statistic.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"","code":"auc.nonpara.mw(x, y, conf.level=0.95,                   method=c(\"newcombe\", \"pepe\", \"delong\",                            \"jackknife\", \"bootstrapP\", \"bootstrapBCa\"),                   nboot)"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"x vector observations class P. y vector observations class N. conf.level confidence level interval. default \t0.95. method method used construct CI. newcombe \tmethod recommended Newcombe (2006); pepe method \tproposed Pepe (2003); delong method proposed \tDelong et al. (1988); jackknife uses \tjackknife method; bootstrapP uses bootstrap \tpercentile CI; bootstrapBCa uses bootstrap \tbias-corrected accelerated CI. default newcombe. can abbreviated. nboot number bootstrap iterations.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"function implements various methods based Mann-Whitney statistic.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"observations class P tend larger values class N. help-file copy original help-file function auc.nonpara.mw auRoc-package. important note   , using method=\"pepe\", confidence interval computed documented Qin Hotilovac (2008)   different original function.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"Point estimate lower upper bounds CI AUC.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/auc.nonpara.mw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"AUC Based on the Mann-Whitney Statistic — auc.nonpara.mw","text":"Elizabeth R Delong, David M Delong, Daniel L Clarke-Pearson (1988)   Comparing areas two correlated receiver operating characteristic curves: nonparametric approach.   Biometrics   44 837-845 Dai Feng, Giuliana Cortese, Richard Baumgartner (2015)   comparison confidence/credible interval methods   area ROC curve continuous diagnostic tests   small sample size.   Statistical Methods Medical Research   DOI: 10.1177/0962280215602040 Robert G Newcombe (2006)   Confidence intervals effect size measure based Mann-Whitney statistic. Part 2: asymptotic methods evaluation.   Statistics medicine   25(4) 559-573 Margaret Sullivan Pepe (2003)   statistical evaluation medical tests classification prediction.   Oxford University Press Qin, G., & Hotilovac, L. (2008). Comparison non-parametric confidence intervals area ROC curve continuous-scale   diagnostic test. Statistical Methods Medical Research, 17(2), pp. 207-21","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/CalibrationCurves.html","id":null,"dir":"Reference","previous_headings":"","what":"General information on package and val.prob.ci.2 function — CalibrationCurves","title":"General information on package and val.prob.ci.2 function — CalibrationCurves","text":"years ago, Yvonne Vergouwe Ewout Steyerberg adapted function val.prob rms-package (https://cran.r-project.org/package=rms) val.prob.ci added following functions val.prob: Scaled Brier score relating max average calibrated Null model Risk distribution according outcome 0 1 indicate outcome label; set d1lab=\"..\", d0lab=\"..\" Labels: y axis: \"Observed Frequency\"; Triangle: \"Grouped observations\" Confidence intervals around triangles cut-can plotted; set x coordinate December 2015, Bavo De Cock, Daan Nieboer, Ben Van Calster adapted val.prob.ci.2: Flexible calibration curves can obtained using loess (default)     restricted cubic splines, pointwise 95% confidence intervals. Flexible calibration curves now given default decision based findings reported Van Calster et al. (2016). Loess: confidence intervals can obtained closed form using bootstrapping     (CL.BT=T bootstrapping 2000 bootstrap samples, however     take ) RCS: 3 5 knots can used knot locations estimated using default quantiles          x (rcspline.eval, see rcspline.plot rcspline.eval) estimation problems occur specified number knots          (nr.knots, default 5), analysis repeated           nr.knots-1 problem disappeared function stops still estimation problem 3 knots can now adjust plot use normal plot commands     (cex.axis etcetera), size legend now specified     cex.leg Label y-axis: \"Observed proportion\" Stats: added Estimated Calibration Index (ECI), statistical     measure quantify lack calibration (Van Hoorde et al., 2015) Stats shown plot: default show \"abc\" model performance (Steyerberg et al., 2011). , calibration intercept (calibration---large), calibration slope c-     statistic. Alternatively, user can select statistics     choice (e.g. dostats=c(\"C (ROC)\",\"R2\") dostats=c(2,3). Vectors p, y logit longer sorted Since , several new features added still added. current version package can always found https://github.com/BavoDC can easily installed using following code:  install.packages(\"devtools\") # yet installed require(devtools) install_git(\"https://github.com/BavoDC/CalibrationCurves\")","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/CalibrationCurves.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"General information on package and val.prob.ci.2 function — CalibrationCurves","text":"Steyerberg, E.W.Van Calster, B., Pencina, M.J. (2011). Performance measures prediction models markers : evaluation predictions classifications. Revista Espanola de Cardiologia, 64(9), pp. 788-794 Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina M., Steyerberg E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176 Van Hoorde, K., Van Huffel, S., Timmerman, D., Bourne, T., Van Calster, B. (2015). spline-based tool assess visualize calibration multiclass risk predictions. Journal Biomedical Informatics, 54, pp. 283-93","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/dot-rcspline.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function — .rcspline.plot","title":"Internal function — .rcspline.plot","text":"Adjusted version rcspline.plot function output returned plot made","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/dot-rcspline.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function — .rcspline.plot","text":"","code":".rcspline.plot(   x,   y,   model = c(\"logistic\", \"cox\", \"ols\"),   xrange,   event,   nk = 5,   knots = NULL,   show = c(\"xbeta\", \"prob\"),   adj = NULL,   xlab,   ylab,   ylim,   plim = c(0, 1),   plotcl = TRUE,   showknots = TRUE,   add = FALSE,   plot = TRUE,   subset,   lty = 1,   noprint = FALSE,   m,   smooth = FALSE,   bass = 1,   main = \"auto\",   statloc )"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/dot-rcspline.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function — .rcspline.plot","text":"x numeric predictor y numeric response. binary logistic regression, y either 0 1. model \"logistic\" \"cox\". \"cox\", uses coxph.fit function method=\"efron\" arguement set. xrange range evaluating x, default \\(f\\) \\(1 - f\\) quantiles x, \\(f = \\frac{10}{\\max{(n, 200)}}\\) \\(n\\) number observations event event/censoring indicator model=\"cox\". event present, model assumed \"cox\" nk number knots knots knot locations, default based quantiles x (rcspline.eval) show \"xbeta\" \"prob\" - plotted y-axis adj optional matrix adjustment variables xlab x-axis label, default “label” attribute x ylab y-axis label, default “label” attribute y ylim y-axis limits logit log hazard plim y-axis limits probability scale plotcl plot confidence limits showknots show knot locations arrows add add plot already existing plot plot logical indicate whether plot made. FALSE suppresses plot. subset subset observations process, e.g. sex == \"male\" lty line type plotting estimated spline function noprint suppress printing regression coefficients standard errors m model=\"logistic\", plot grouped estimates triangles. group contains m ordered observations x. smooth plot nonparametric estimate model=\"logistic\" adj specified bass smoothing parameter (see supsmu) main main title, default \"Estimated Spline Transformation\" statloc location summary statistics. Default positioning clicking left mouse button upper left corner statistics appear. Alternative \"ll\" place graph lower left, actual x y coordinates. Use \"none\" suppress statistics.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/dot-rcspline.plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function — .rcspline.plot","text":"list components (knots, x, xbeta, lower, upper) respectively knot locations, design matrix, linear predictor, lower upper confidence limits","code":""},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.CalibrationCurve.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for a CalibrationCurve object — print.CalibrationCurve","title":"Print function for a CalibrationCurve object — print.CalibrationCurve","text":"Prints call, confidence level values performance measures.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.CalibrationCurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for a CalibrationCurve object — print.CalibrationCurve","text":"","code":"# S3 method for CalibrationCurve print(x, ...)"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.CalibrationCurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for a CalibrationCurve object — print.CalibrationCurve","text":"x object type CalibrationCurve, resulting val.prob.ci.2. ... arguments passed print","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.CalibrationCurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for a CalibrationCurve object — print.CalibrationCurve","text":"original CalibrationCurve object returned.","code":""},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.ggplotCalibrationCurve.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for a ggplotCalibrationCurve object — print.ggplotCalibrationCurve","title":"Print function for a ggplotCalibrationCurve object — print.ggplotCalibrationCurve","text":"Prints ggplot, call, confidence level values performance measures.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.ggplotCalibrationCurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for a ggplotCalibrationCurve object — print.ggplotCalibrationCurve","text":"","code":"# S3 method for ggplotCalibrationCurve print(x, ...)"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.ggplotCalibrationCurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for a ggplotCalibrationCurve object — print.ggplotCalibrationCurve","text":"x object type ggplotCalibrationCurve, resulting valProbggplot. ... arguments passed print","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/print.ggplotCalibrationCurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for a ggplotCalibrationCurve object — print.ggplotCalibrationCurve","text":"original ggplotCalibrationCurve object returned.","code":""},{"path":[]},{"path":"https://bavodc.github.io/CalibrationCurves/reference/traindata.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data sets to illustrate the package functionality — simulateddata","title":"Simulated data sets to illustrate the package functionality — simulateddata","text":"traindata testdata dataframe synthetically generated data sets illustrate functionality package.   traindata 1000 observations testdata 500 observations. settings used generate data   sets.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/traindata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data sets to illustrate the package functionality — simulateddata","text":"","code":"data(traindata)   data(testdata)"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/traindata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data sets to illustrate the package functionality — simulateddata","text":"y binary outcome variable x1 covariate 1 x1 covariate 2 x1 covariate 3 x1 covariate 4","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/traindata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated data sets to illustrate the package functionality — simulateddata","text":"See examples data sets generated.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/traindata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data sets to illustrate the package functionality — simulateddata","text":"","code":"# The data sets were generated as follows   set.seed(1782)    # Simulate training data   nTrain    = 1000   B         = c(0.1, 0.5, 1.2, -0.75, 0.8)   X         = replicate(4, rnorm(nTrain))   p0true    = binomial()$linkinv(cbind(1, X) %*% B)   y         = rbinom(nTrain, 1, p0true)   colnames(X) = paste0(\"x\", seq_len(ncol(X)))   traindata = data.frame(y, X)    # Simulate validation data   nTest    = 500   X        = replicate(4, rnorm(nTest))   p0true   = binomial()$linkinv(cbind(1, X) %*% B)   y        = rbinom(nTest, 1, p0true)   colnames(X) = paste0(\"x\", seq_len(ncol(X)))   testdata = data.frame(y, X)"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibration performance — val.prob.ci.2","title":"Calibration performance — val.prob.ci.2","text":"function val.prob.ci.2 adaptation val.prob Frank Harrell's rms package, https://cran.r-project.org/package=rms. Hence, description functions val.prob.ci.2 come original val.prob.  key feature val.prob.ci.2 generation logistic flexible calibration curves related statistics. using code, please cite: Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina, M.J., Steyerberg, E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibration performance — val.prob.ci.2","text":"","code":"val.prob.ci.2(   p,   y,   logit,   group,   weights = rep(1, length(y)),   normwt = FALSE,   pl = TRUE,   smooth = c(\"loess\", \"rcs\", \"none\"),   CL.smooth = \"fill\",   CL.BT = FALSE,   lty.smooth = 1,   col.smooth = \"black\",   lwd.smooth = 1,   nr.knots = 5,   logistic.cal = FALSE,   lty.log = 1,   col.log = \"black\",   lwd.log = 1,   xlab = \"Predicted probability\",   ylab = \"Observed proportion\",   xlim = c(-0.02, 1),   ylim = c(-0.15, 1),   m,   g,   cuts,   emax.lim = c(0, 1),   legendloc = c(0.5, 0.27),   statloc = c(0, 0.85),   dostats = TRUE,   cl.level = 0.95,   method.ci = \"pepe\",   roundstats = 2,   riskdist = \"predicted\",   cex = 0.75,   cex.leg = 0.75,   connect.group = FALSE,   connect.smooth = TRUE,   g.group = 4,   evaluate = 100,   nmin = 0,   d0lab = \"0\",   d1lab = \"1\",   cex.d01 = 0.7,   dist.label = 0.04,   line.bins = -0.05,   dist.label2 = 0.03,   cutoff,   las = 1,   length.seg = 1,   y.intersp = 1,   lty.ideal = 1,   col.ideal = \"red\",   lwd.ideal = 1,   allowPerfectPredictions = FALSE,   ... )"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibration performance — val.prob.ci.2","text":"p predicted probability y vector binary outcomes logit predicted log odds outcome.  Specify either p logit. group grouping variable.  numeric variable grouped g.group quantile groups (default quartiles).  Set group=TRUE use group algorithm single stratum val.prob. weights optional numeric vector per-observation weights (usually frequencies), used group given. normwt set TRUE make weights sum number non-missing observations. pl TRUE plot calibration curve(s). FALSE calibration curves plotted, statistics still computed outputted. smooth \"loess\" generates flexible calibration curve based loess, \"rcs\" generates calibration curves based restricted cubic splines (see rcs rcspline.plot), \"none\" suppresses flexible curve. recommend use loess unless N large,  example N>5000. Default \"loess\". CL.smooth \"fill\" shows pointwise 95% confidence limits flexible calibration curve gray area lower upper limits, TRUE shows pointwise 95% confidence limits flexible calibration curve  dashed lines, FALSE suppresses confidence limits. Default \"fill\". CL.BT TRUE uses confidence limits based 2000 bootstrap samples, FALSE uses closed form confidence limits. Default FALSE. lty.smooth linetype flexible calibration curve. Default 1. col.smooth color flexible calibration curve. Default \"black\". lwd.smooth line width flexible calibration curve. Default 1. nr.knots specifies number knots rcs-based calibration curve. default well highest allowed value 5. case specified number knots leads estimation problems, number knots automatically reduced closest  value without estimation problems. logistic.cal TRUE plots logistic calibration curve, FALSE suppresses curve. Default FALSE. lty.log logistic.cal=TRUE, linetype logistic calibration curve. Default 1. col.log logistic.cal=TRUE, color logistic calibration curve. Default \"black\". lwd.log logistic.cal=TRUE, line width logistic calibration curve. Default 1. xlab x-axis label, default \"Predicted Probability\". ylab y-axis label, default \"Observed proportion\". xlim, ylim numeric vectors length 2, giving x y coordinates ranges (see plot.window) m grouped proportions desired, average . observations per group g grouped proportions desired, number quantile groups cuts grouped proportions desired, actual cut points constructing intervals, e.g. c(0,.1,.8,.9,1) seq(0,1,=.2) emax.lim Vector containing lowest highest predicted probability compute Emax. legendloc pl=TRUE, list components x,y vector c(x,y) bottom right corner legend curves points. Default c(.50, .27) scaled lim. Use locator(1) use mouse, FALSE suppress legend. statloc \"abc\" model performance (Steyerberg et al., 2011)-calibration intercept, calibration slope, c statistic-added plot, using statloc upper left corner box (default c(0,.85). can specify list vector. Use locator(1) mouse, FALSE suppress statistics. plotted curve legends. dostats specifies whether performance measures shown figure. TRUE shows \"abc\" model performance (Steyerberg et al., 2011): calibration intercept, calibration slope,  c-statistic. TRUE default.  FALSE suppresses presentation statistics figure. c() list specific stats shows specified  stats. key stats also mentioned paper \"C (ROC)\" c statistic, \"Intercept\"  calibration intercept, \"Slope\" calibration slope, \"ECI\" estimated calibration index  (Van Hoorde et al, 2015). full list possible statistics taken val.prob  augmented estimated calibration index: \"Dxy\", \"C (ROC)\", \"R2\", \"D\", \"D:Chi-sq\", \"D:p\", \"U\", \"U:Chi-sq\",   \"U:p\", \"Q\", \"Brier\", \"Intercept\", \"Slope\", \"Emax\", \"Brier scaled\", \"Eavg\", \"ECI\". statistics always returned function. cl.level dostats=TRUE, confidence level calculation confidence intervals calibration intercept, calibration slope c-statistic. Default 0.95. method.ci method calculate confidence interval c-statistic. argument passed auc.nonpara.mw auRoc-package possible methods compute confidence interval \"newcombe\", \"pepe\", \"delong\" \"jackknife\". Bootstrap-based methods available. default method \"pepe\" , confidence interval logit-transformation-based confidence interval documented Qin Hotilovac (2008). See auc.nonpara.mw information methods. roundstats specifies number decimals statistics rounded shown plot. Default 2. riskdist Use \"calibrated\" plot relative frequency distribution calibrated probabilities dividing 101 bins lim[1] lim[2]. Set \"predicted\" (default rms 4.5-1) use raw assigned risk, FALSE omit risk distribution. Values scaled highest bar 0.15*(lim[2]-lim[1]). cex, cex.leg controls font size statistics (cex) plot legend (cex.leg). Default 0.75 connect.group Defaults FALSE represent group fractions triangles. Set TRUE also connect solid line. connect.smooth Defaults TRUE draw smoothed estimates using line. Set FALSE instead use dots individual estimates g.group number quantile groups use group given variable numeric. evaluate number points store lowess-calibration curve. Default 100.  evaluate unique predicted probabilities, evaluate equally-spaced quantiles unique predicted probabilities, linearly interpolated calibrated values, retained plotting (stored object returned val.prob. nmin applies group given.  nmin \\(> 0\\), val.prob store coordinates smoothed calibration curves outer tails, fewer nmin raw observations represented tails.  example nmin=50, plot function plot estimated calibration curve \\(\\) \\(b\\), 50 subjects predicted probabilities \\(< \\) \\(> b\\). nmin ignored computing accuracy statistics. d0lab, d1lab controls labels events non-events (.e. outcome y) histograms. Defaults d1lab=\"1\" events d0lab=\"0\" non-events. cex.d01 controls size labels events non-events. Default 0.7. dist.label controls horizontal position labels events non-events. Default 0.04. line.bins controls horizontal (y-axis) position histograms. Default -0.05. dist.label2 controls vertical distance labels events non-events. Default 0.03. cutoff puts arrow specified risk cut-(s). Default none. las controls whether y-axis values shown horizontally (1) vertically (0). length.seg controls length histogram lines. Default 1. y.intersp character interspacing vertical line distances legend (legend) lty.ideal linetype ideal line. Default 1. col.ideal controls color ideal line plot. Default \"red\". lwd.ideal controls line width ideal line plot. Default 1. allowPerfectPredictions Logical, indicates whether perfect predictions (.e. values either 0 1) allowed. Default FALSE, since transform predictions using logit transformation calculate calibration measures. case 0 1, results minus infinity infinity, respectively. allowPerfectPredictions = TRUE, 0 1 replaced 1e-8 1 - 1e-8, respectively. ... arguments passed plot, see par","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibration performance — val.prob.ci.2","text":"object type CalibrationCurve following slots: call matched call. stats vector containing performance measures calibration. cl.level confidence level used. Calibration contains calibration intercept slope, together confidence intervals. Cindex value c-statistic, together confidence interval. warningMessages , warning messages printed running function. CalibrationCurves coordinates plotting calibration curves.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibration performance — val.prob.ci.2","text":"using predicted probabilities uninformative model (.e. equal probabilities observations), model predictive value.  Consequently, applicable, value performance measure corresponds worst possible theoretical value. ECI, example, equals 1 (Edlinger et al., 2022).","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calibration performance — val.prob.ci.2","text":"order make use (functions) package auRoc, user needs install JAGS. However, since package uses auc.nonpara.mw function depend use JAGS, therefore copied code slightly adjusted method=\"pepe\".","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibration performance — val.prob.ci.2","text":"Edlinger, M, van Smeden, M, Alber, HF, Wanitschek, M, Van Calster, B. (2022). Risk prediction models discrete ordinal outcomes: Calibration impact proportional odds assumption. Statistics Medicine, 41( 8), pp. 1334– 1360 Qin, G., & Hotilovac, L. (2008). Comparison non-parametric confidence intervals area ROC curve continuous-scale diagnostic test. Statistical Methods Medical Research, 17(2), pp. 207-21 Steyerberg, E.W., Van Calster, B., Pencina, M.J. (2011). Performance measures prediction models markers : evaluation predictions classifications. Revista Espanola de Cardiologia, 64(9), pp. 788-794 Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina M., Steyerberg E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176 Van Hoorde, K., Van Huffel, S., Timmerman, D., Bourne, T., Van Calster, B. (2015). spline-based tool assess visualize calibration multiclass risk predictions. Journal Biomedical Informatics, 54, pp. 283-93","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/val.prob.ci.2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibration performance — val.prob.ci.2","text":"","code":"# Load package library(CalibrationCurves) set.seed(1783)  # Simulate training data X      = replicate(4, rnorm(5e2)) p0true = binomial()$linkinv(cbind(1, X) %*% c(0.1, 0.5, 1.2, -0.75, 0.8)) y      = rbinom(5e2, 1, p0true) Df     = data.frame(y, X)  # Fit logistic model FitLog = lrm(y ~ ., Df)  # Simulate validation data Xval   = replicate(4, rnorm(5e2)) p0true = binomial()$linkinv(cbind(1, Xval) %*% c(0.1, 0.5, 1.2, -0.75, 0.8)) yval   = rbinom(5e2, 1, p0true) Pred   = binomial()$linkinv(cbind(1, Xval) %*% coef(FitLog))  # Default calibration plot val.prob.ci.2(Pred, yval)  #> Call: #> val.prob.ci.2(p = Pred, y = yval) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083   # Adding logistic calibration curves and other additional features val.prob.ci.2(Pred, yval, CL.smooth = TRUE, logistic.cal = TRUE, lty.log = 2,  col.log = \"red\", lwd.log = 1.5)  #> Call: #> val.prob.ci.2(p = Pred, y = yval, CL.smooth = TRUE, logistic.cal = TRUE,  #>     lty.log = 2, col.log = \"red\", lwd.log = 1.5) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083   val.prob.ci.2(Pred, yval, CL.smooth = TRUE, logistic.cal = TRUE, lty.log = 9, col.log = \"red\", lwd.log = 1.5, col.ideal = colors()[10], lwd.ideal = 0.5)  #> Call: #> val.prob.ci.2(p = Pred, y = yval, CL.smooth = TRUE, logistic.cal = TRUE,  #>     lty.log = 9, col.log = \"red\", lwd.log = 1.5, col.ideal = colors()[10],  #>     lwd.ideal = 0.5) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibration performance: ggplot version — valProbggplot","title":"Calibration performance: ggplot version — valProbggplot","text":"function valProbggplot adaptation val.prob Frank Harrell's rms package, https://cran.r-project.org/package=rms. Hence, description functions valProbggplot come original val.prob.  key feature valProbggplot generation logistic flexible calibration curves related statistics. using code, please cite: Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina, M.J., Steyerberg, E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibration performance: ggplot version — valProbggplot","text":"","code":"valProbggplot(   p,   y,   logit,   group,   weights = rep(1, length(y)),   normwt = FALSE,   pl = TRUE,   smooth = c(\"loess\", \"rcs\", \"none\"),   CL.smooth = \"fill\",   CL.BT = FALSE,   lty.smooth = 1,   col.smooth = \"black\",   lwd.smooth = 1,   nr.knots = 5,   logistic.cal = FALSE,   lty.log = 1,   col.log = \"black\",   lwd.log = 1,   xlab = \"Predicted probability\",   ylab = \"Observed proportion\",   xlim = c(-0.02, 1),   ylim = c(-0.15, 1),   m,   g,   cuts,   emax.lim = c(0, 1),   legendloc = c(0.5, 0.27),   statloc = c(0, 0.85),   dostats = TRUE,   cl.level = 0.95,   method.ci = \"pepe\",   roundstats = 2,   riskdist = \"predicted\",   size = 3,   size.leg = 5,   connect.group = FALSE,   connect.smooth = TRUE,   g.group = 4,   evaluate = 100,   nmin = 0,   d0lab = \"0\",   d1lab = \"1\",   size.d01 = 5,   dist.label = 0.01,   line.bins = -0.05,   dist.label2 = 0.04,   cutoff,   length.seg = 0.85,   lty.ideal = 1,   col.ideal = \"red\",   lwd.ideal = 1,   allowPerfectPredictions = FALSE )"},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibration performance: ggplot version — valProbggplot","text":"p predicted probability y vector binary outcomes logit predicted log odds outcome.  Specify either p logit. group grouping variable.  numeric variable grouped g.group quantile groups (default quartiles).  Set group=TRUE use group algorithm single stratum val.prob. weights optional numeric vector per-observation weights (usually frequencies), used group given. normwt set TRUE make weights sum number non-missing observations. pl TRUE plot calibration curve(s). FALSE calibration curves plotted, statistics still computed outputted. smooth \"loess\" generates flexible calibration curve based loess, \"rcs\" generates calibration curves based restricted cubic splines (see rcs rcspline.plot), \"none\" suppresses flexible curve. recommend use loess unless N large,  example N>5000. Default \"loess\". CL.smooth \"fill\" shows pointwise 95% confidence limits flexible calibration curve gray area lower upper limits, TRUE shows pointwise 95% confidence limits flexible calibration curve  dashed lines, FALSE suppresses confidence limits. Default \"fill\". CL.BT TRUE uses confidence limits based 2000 bootstrap samples, FALSE uses closed form confidence limits. Default FALSE. lty.smooth linetype flexible calibration curve. Default 1. col.smooth color flexible calibration curve. Default \"black\". lwd.smooth line width flexible calibration curve. Default 1. nr.knots specifies number knots rcs-based calibration curve. default well highest allowed value 5. case specified number knots leads estimation problems, number knots automatically reduced closest  value without estimation problems. logistic.cal TRUE plots logistic calibration curve, FALSE suppresses curve. Default FALSE. lty.log logistic.cal=TRUE, linetype logistic calibration curve. Default 1. col.log logistic.cal=TRUE, color logistic calibration curve. Default \"black\". lwd.log logistic.cal=TRUE, line width logistic calibration curve. Default 1. xlab x-axis label, default \"Predicted Probability\". ylab y-axis label, default \"Observed proportion\". xlim, ylim numeric vectors length 2, giving x y coordinates ranges (see xlim ylim). m grouped proportions desired, average . observations per group g grouped proportions desired, number quantile groups cuts grouped proportions desired, actual cut points constructing intervals, e.g. c(0,.1,.8,.9,1) seq(0,1,=.2) emax.lim Vector containing lowest highest predicted probability compute Emax. legendloc pl=TRUE, list components x,y vector c(x,y) bottom right corner legend curves points. Default c(.50, .27) scaled lim. Use locator(1) use mouse, FALSE suppress legend. statloc \"abc\" model performance (Steyerberg et al., 2011)-calibration intercept, calibration slope, c statistic-added plot, using statloc upper left corner box (default c(0,.85). can specify list vector. Use locator(1) mouse, FALSE suppress statistics. plotted curve legends. dostats specifies whether performance measures shown figure. TRUE shows \"abc\" model performance (Steyerberg et al., 2011): calibration intercept, calibration slope,  c-statistic. TRUE default.  FALSE suppresses presentation statistics figure. c() list specific stats shows specified  stats. key stats also mentioned paper \"C (ROC)\" c statistic, \"Intercept\"  calibration intercept, \"Slope\" calibration slope, \"ECI\" estimated calibration index  (Van Hoorde et al, 2015). full list possible statistics taken val.prob  augmented estimated calibration index: \"Dxy\", \"C (ROC)\", \"R2\", \"D\", \"D:Chi-sq\", \"D:p\", \"U\", \"U:Chi-sq\",   \"U:p\", \"Q\", \"Brier\", \"Intercept\", \"Slope\", \"Emax\", \"Brier scaled\", \"Eavg\", \"ECI\". statistics always returned function. cl.level dostats=TRUE, confidence level calculation confidence intervals calibration intercept, calibration slope c-statistic. Default 0.95. method.ci method calculate confidence interval c-statistic. argument passed auc.nonpara.mw auRoc-package possible methods compute confidence interval \"newcombe\", \"pepe\", \"delong\" \"jackknife\". Bootstrap-based methods available. default method \"pepe\" , confidence interval logit-transformation-based confidence interval documented Qin Hotilovac (2008). See auc.nonpara.mw information methods. roundstats specifies number decimals statistics rounded shown plot. Default 2. riskdist Use \"calibrated\" plot relative frequency distribution calibrated probabilities dividing 101 bins lim[1] lim[2]. Set \"predicted\" (default rms 4.5-1) use raw assigned risk, FALSE omit risk distribution. Values scaled highest bar 0.15*(lim[2]-lim[1]). size, size.leg controls font size statistics (size) plot legend (size.leg). Default 3 5, respectively. connect.group Defaults FALSE represent group fractions triangles. Set TRUE also connect solid line. connect.smooth Defaults TRUE draw smoothed estimates using line. Set FALSE instead use dots individual estimates g.group number quantile groups use group given variable numeric. evaluate number points store lowess-calibration curve. Default 100.  evaluate unique predicted probabilities, evaluate equally-spaced quantiles unique predicted probabilities, linearly interpolated calibrated values, retained plotting (stored object returned val.prob. nmin applies group given.  nmin \\(> 0\\), val.prob store coordinates smoothed calibration curves outer tails, fewer nmin raw observations represented tails.  example nmin=50, plot function plot estimated calibration curve \\(\\) \\(b\\), 50 subjects predicted probabilities \\(< \\) \\(> b\\). nmin ignored computing accuracy statistics. d0lab, d1lab controls labels events non-events (.e. outcome y) histograms. Defaults d1lab=\"1\" events d0lab=\"0\" non-events. size.d01 controls size labels events non-events. Default 5. dist.label controls horizontal position labels events non-events. Default 0.01. line.bins controls horizontal (y-axis) position histograms. Default -0.05. dist.label2 controls vertical distance labels events non-events. Default 0.03. cutoff puts arrow specified risk cut-(s). Default none. length.seg controls length histogram lines. Default 0.85. lty.ideal linetype ideal line. Default 1. col.ideal controls color ideal line plot. Default \"red\". lwd.ideal controls line width ideal line plot. Default 1. allowPerfectPredictions Logical, indicates whether perfect predictions (.e. values either 0 1) allowed. Default FALSE, since transform predictions using logit transformation calculate calibration measures. case 0 1, results minus infinity infinity, respectively. allowPerfectPredictions = TRUE, 0 1 replaced 1e-8 1 - 1e-8, respectively.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibration performance: ggplot version — valProbggplot","text":"object type ggplotCalibrationCurve following slots: call matched call. ggPlot ggplot object. stats vector containing performance measures calibration. cl.level confidence level used. Calibration contains calibration intercept slope, together confidence intervals. Cindex value c-statistic, together confidence interval. warningMessages , warning messages printed running function. CalibrationCurves coordinates plotting calibration curves.","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calibration performance: ggplot version — valProbggplot","text":"using predicted probabilities uninformative model (.e. equal probabilities observations), model predictive value.  Consequently, applicable, value performance measure corresponds worst possible theoretical value. ECI, example, equals 1 (Edlinger et al., 2022).","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calibration performance: ggplot version — valProbggplot","text":"order make use (functions) package auRoc, user needs install JAGS. However, since package uses auc.nonpara.mw function depend use JAGS, therefore copied code slightly adjusted method=\"pepe\".","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calibration performance: ggplot version — valProbggplot","text":"Edlinger, M, van Smeden, M, Alber, HF, Wanitschek, M, Van Calster, B. (2022). Risk prediction models discrete ordinal outcomes: Calibration impact proportional odds assumption. Statistics Medicine, 41( 8), pp. 1334– 1360 Qin, G., & Hotilovac, L. (2008). Comparison non-parametric confidence intervals area ROC curve continuous-scale diagnostic test. Statistical Methods Medical Research, 17(2), pp. 207-21 Steyerberg, E.W., Van Calster, B., Pencina, M.J. (2011). Performance measures prediction models markers : evaluation predictions classifications. Revista Espanola de Cardiologia, 64(9), pp. 788-794 Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina M., Steyerberg E.W. (2016). calibration hierarchy risk models defined: utopia empirical data. Journal Clinical Epidemiology, 74, pp. 167-176 Van Hoorde, K., Van Huffel, S., Timmerman, D., Bourne, T., Van Calster, B. (2015). spline-based tool assess visualize calibration multiclass risk predictions. Journal Biomedical Informatics, 54, pp. 283-93","code":""},{"path":"https://bavodc.github.io/CalibrationCurves/reference/valProbggplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibration performance: ggplot version — valProbggplot","text":"","code":"# Load package library(CalibrationCurves) set.seed(1783)  # Simulate training data X      = replicate(4, rnorm(5e2)) p0true = binomial()$linkinv(cbind(1, X) %*% c(0.1, 0.5, 1.2, -0.75, 0.8)) y      = rbinom(5e2, 1, p0true) Df     = data.frame(y, X)  # Fit logistic model FitLog = lrm(y ~ ., Df)  # Simulate validation data Xval   = replicate(4, rnorm(5e2)) p0true = binomial()$linkinv(cbind(1, Xval) %*% c(0.1, 0.5, 1.2, -0.75, 0.8)) yval   = rbinom(5e2, 1, p0true) Pred   = binomial()$linkinv(cbind(1, Xval) %*% coef(FitLog))  # Default calibration plot valProbggplot(Pred, yval)  #> Call: #> valProbggplot(p = Pred, y = yval) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083   # Adding logistic calibration curves and other additional features valProbggplot(Pred, yval, CL.smooth = TRUE, logistic.cal = TRUE, lty.log = 2,  col.log = \"red\", lwd.log = 1.5)  #> Call: #> valProbggplot(p = Pred, y = yval, CL.smooth = TRUE, logistic.cal = TRUE,  #>     lty.log = 2, col.log = \"red\", lwd.log = 1.5) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083   valProbggplot(Pred, yval, CL.smooth = TRUE, logistic.cal = TRUE, lty.log = 9, col.log = \"red\", lwd.log = 1.5, col.ideal = colors()[10], lwd.ideal = 0.5)  #> Call: #> valProbggplot(p = Pred, y = yval, CL.smooth = TRUE, logistic.cal = TRUE,  #>     lty.log = 9, col.log = \"red\", lwd.log = 1.5, col.ideal = colors()[10],  #>     lwd.ideal = 0.5) #>  #> A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic.  #>  #>          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p  #>   0.60048690   0.80024345   0.35491505   0.30737619 154.68809420   0.00000000  #>            U     U:Chi-sq          U:p            Q        Brier    Intercept  #>   0.01384033   8.92016298   0.01156142   0.29353586   0.18549917   0.18828469  #>        Slope         Emax Brier scaled         Eavg          ECI  #>   0.79397043   0.08026282   0.25724275   0.05093656   0.37394083"}]
