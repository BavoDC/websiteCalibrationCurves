<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="CalibrationCurves">
<title>Introduction to the CalibrationCurves package • CalibrationCurves</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to the CalibrationCurves package">
<meta property="og:description" content="CalibrationCurves">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">CalibrationCurves</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.6</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/CalibrationCurves.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">


<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Introduction to the CalibrationCurves package</h1>
                        <h4 data-toc-skip class="author">Bavo De Cock Campo</h4>
            
            <h4 data-toc-skip class="date">2025-07-04</h4>
      
      
      <div class="d-none name"><code>CalibrationCurves.Rmd</code></div>
    </div>

    
    
<div>
<p><img src="CalibrationCurves.png" width="25%"></p>
</div>
<p><br clear="right">
In this document, we give you a brief overview of the basic functionality of the <code>CalibrationCurves</code> package. In addition, we present the theoretical framework behind calibration and provide some illustrative examples to give the reader a better insight into the calibration assessment of a predictive model. We advise you to also consult the help-pages of the functions to get an exhaustive overview of the functionality.</p>
<p>We tried to tailor the explanation of the concepts to professionals with different backgrounds. Please, do contact me if you feel that something is unclear so that I can adjust (and hopefully improve) it. In addition, don’t hesitate to send any suggestions you might have and bug reports to the package author.</p>
<div class="section level2" number="1">
<h2 id="assessing-the-performance-of-risk-prediction-models">
<span class="header-section-number">1</span> Assessing the performance of risk prediction models<a class="anchor" aria-label="anchor" href="#assessing-the-performance-of-risk-prediction-models"></a>
</h2>
<div class="section level3" number="1.1">
<h3 id="risk-prediction-models">
<span class="header-section-number">1.1</span> Risk prediction models<a class="anchor" aria-label="anchor" href="#risk-prediction-models"></a>
</h3>
<p>In this package, we focus on risk prediction models that estimate the probability <span class="math inline">\(\pi_i\)</span> of observing an event. We use <span class="math inline">\(y_i \in (0, 1)\)</span> to denote the variable that captures this outcome which takes on the value 0 in case of a non-event and 1 in case of an event. Here, <span class="math inline">\(i\)</span> serves as an index for the observations (mostly the patient within medical predictive analytics) with <span class="math inline">\(i = (1, \dots, n)\)</span> and where <span class="math inline">\(n\)</span> denotes the total number of observations. We assume that the response variable <span class="math inline">\(y_i\)</span> follows a Bernoulli distribution <span class="math inline">\(y_i \sim \text{Bern}(\pi_i)\)</span>.</p>
<p>For example, we could be interested in estimating the probability <span class="math inline">\(\pi_i\)</span> of observing a malignant tumour for patient <span class="math inline">\(i\)</span>. In this case, the event <span class="math inline">\(y_i = 1\)</span> is the tumour being malignant and <span class="math inline">\(y_i = 0\)</span> when the tumour is benign. With no available information on the patient characteristics, we might rely on the prevalence in the general population to estimate this probability.</p>
<p>Using risk prediction models, we model the outcome as a function of the observed risk/patient characteristics. The risk characteristics are contained in the covariate vector <span class="math inline">\(\boldsymbol{x}_i\)</span>. This vector contains all observed information for patient <span class="math inline">\(i\)</span> (e.g. maximum diameter of the lesion, proportion of solid tissue, …). This allows us to obtain a more accurate prediction that is based on the relation between the patient characteristics and the outcome. To construct a clinical prediction model, we either rely on a statistical models such as logistic regression or machine learning methods. A general expression that encompasses both types of models is
<span class="math display">\[\begin{align*}
E[y_i | \boldsymbol{x}_i] = f(\boldsymbol{x}_i).
\end{align*}\]</span>
This expression states that we model the response <span class="math inline">\(y_i\)</span> as a function of the observed risk characteristics <span class="math inline">\(\boldsymbol{x}_i\)</span>.</p>
<div class="section level4" number="1.1.1">
<h4 id="mathematical-details-on-existing-predictive-models">
<span class="header-section-number">1.1.1</span> Mathematical details on existing predictive models<a class="anchor" aria-label="anchor" href="#mathematical-details-on-existing-predictive-models"></a>
</h4>
<p>To construct a risk prediction model, we could rely on a logistic regression model
<span class="math display">\[\begin{align*}
E[y_i | \boldsymbol{x}_i] = \pi_i(\boldsymbol{\beta}) = \frac{e^{\boldsymbol{x}_i^\top \boldsymbol{\beta}}}{1 + e^{\boldsymbol{x}_i^\top \boldsymbol{\beta}}}
\end{align*}\]</span>
where <span class="math inline">\(\boldsymbol{\beta}\)</span> denotes the parameter vector. <span class="math inline">\(\pi_i(\boldsymbol{\beta}) = P(y_i = 1| \boldsymbol{x}_i)\)</span> denotes the probability of observing the event, given the covariate vector <span class="math inline">\(\boldsymbol{x}_i\)</span>. We can rewrite the equation to its more well-known form
<span class="math display">\[\begin{align*}
\log\left( \frac{\pi_i(\boldsymbol{\beta})}{1 - \pi_i(\boldsymbol{\beta})} \right) &amp;= \boldsymbol{x}_i^\top \boldsymbol{\beta}\\[0.5em]
\text{logit}(\pi_i(\boldsymbol{\beta})) &amp;= \eta_i
\end{align*}\]</span>
where <span class="math inline">\(\eta_i\)</span> denotes the linear predictor. Here, we have the well-known logit function at the left side of the equation.</p>
<p>With machine learning methods, <span class="math inline">\(f(\cdot)\)</span> depends on the specific algorithm. With tree-based methods, for example, this correspond to the observed proportion in the leaf nodes. For neural networks, <span class="math inline">\(f(\cdot)\)</span> is determined by the weights in the layers and the chosen activation functions.</p>
</div>
</div>
<div class="section level3" number="1.2">
<h3 id="different-aspects-of-the-predictive-performance">
<span class="header-section-number">1.2</span> Different aspects of the predictive performance<a class="anchor" aria-label="anchor" href="#different-aspects-of-the-predictive-performance"></a>
</h3>
<p>To assess how well the model is able to predict (the probability of) the outcome, we assess two different aspects of the model <span class="citation">(Van Calster et al. 2016, 2019; Alba et al. 2017)</span>:</p>
<ol style="list-style-type: lower-alpha">
<li>
<em>discrimination</em>;</li>
<li>
<em>calibration</em>.</li>
</ol>
<p>With <em>discrimination</em>, we refer to the model’s ability to differentiate between observations that have the event and observations that have not. In this context, this translates to giving higher risk estimates for patients with the event than patients without the event. We commonly assess this using the area under the receiver operating characteristic curve. However, discrimination performance does not tell us how accurate the predictions are. The estimated risk may result in good discrimination and can be inaccurate at the same time. We refer to the accuracy of the predictions as the <em>calibration</em>. Hence, hereby we assess the agreement between the estimated and observed number of events <span class="citation">(Van Calster et al. 2016)</span>. We say that a prediction model is calibrated if the predicted risks correspond to the observed proportions of the event.</p>
</div>
<div class="section level3" number="1.3">
<h3 id="assessing-the-calibration-performance-of-a-risk-prediction-model">
<span class="header-section-number">1.3</span> Assessing the calibration performance of a risk prediction model<a class="anchor" aria-label="anchor" href="#assessing-the-calibration-performance-of-a-risk-prediction-model"></a>
</h3>
<div class="section level4" number="1.3.1">
<h4 id="a-mathematical-perspective">
<span class="header-section-number">1.3.1</span> A mathematical perspective<a class="anchor" aria-label="anchor" href="#a-mathematical-perspective"></a>
</h4>
<p>One way to examine the calibration of risk predictions, is by using calibration curves <span class="citation">(Van Calster et al. 2016, 2019; Steyerberg 2019; De Cock Campo 2023)</span>. A calibration curve maps the predicted probabilities <span class="math inline">\(f(\boldsymbol{x}_i)\)</span> to the actual event probabilities <span class="math inline">\(P(y_i = 1| f(\boldsymbol{x}_i))\)</span> and visualizes the correspondence between the model’s predicted risks and the true probabilities. For perfectly calibrated predictions, the calibration curve equals the diagonal, i.e. <span class="math inline">\(P(y_i = 1 | f(\boldsymbol{x}_i)) = f(\boldsymbol{x}_i) \ \forall \ i\)</span> where <span class="math inline">\(\forall \ i\)</span> denotes for all <span class="math inline">\(i\)</span>.</p>
</div>
<div class="section level4" number="1.3.2">
<h4 id="a-practical-perspective">
<span class="header-section-number">1.3.2</span> A practical perspective<a class="anchor" aria-label="anchor" href="#a-practical-perspective"></a>
</h4>
<p>In practice, we typically assess the model’s calibration on a validation set. In this setting, a calibration curve visualizes the correspondence between the model’s predicted risks and the observed proportion. When we have a perfect agreement between the observed and predicted proportion the calibration curve coincides with the ideal curve (a diagonal line). This scenario is visualized in Figure <a href="#fig:PerfectCalibration">1.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:PerfectCalibration"></span>
<p class="caption">
Figure 1.1: Example of a perfectly calibrated model
</p>
<img src="PerfectCalibration.png" alt="Example of a perfectly calibrated model" width="100%">
</div>
<p>By assessing the calibration performance on a data set other than the training set, we obtain an indication of how well our risk prediction is able to generalize to other data sets and how accurate its out-of-sample predictions are. In general, the prediction model will show some miscalibration and the calibration curve gives us a visual depiction of how badly the model is miscalibrated. The further from the diagonal line, the worse the calibration. Figure <a href="#fig:Overfitted">1.2</a> depicts an example of a model that is miscalibrated and is a typical example of a model that is overfitted to the training data. This particular model has predictions that are too extreme: high risks are overestimated and low risks are underestimated.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Overfitted"></span>
<p class="caption">
Figure 1.2: Example of a miscalibrated model due to overfitting
</p>
<img src="Overfitted.png" alt="Example of a miscalibrated model due to overfitting" width="100%">
</div>
<p>Its counterpart, an underfitted model, occurs less frequently. <a href="#fig:Underfitted">1.3</a> shows the calibration curve of an underfitted model. Here, there is an overestimation for the low risks and an underestimation for the high risks.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Underfitted"></span>
<p class="caption">
Figure 1.3: Example of a miscalibrated model due to underfitting
</p>
<img src="Underfitted.png" alt="Example of a miscalibrated model due to underfitting" width="100%">
</div>
</div>
<div class="section level4" number="1.3.3">
<h4 id="how-do-we-construct-a-calibration-curve">
<span class="header-section-number">1.3.3</span> How do we construct a calibration curve?<a class="anchor" aria-label="anchor" href="#how-do-we-construct-a-calibration-curve"></a>
</h4>
<p>Fitting a logistic regression model to the training data results in an estimate for the parameter vector <span class="math inline">\(\boldsymbol{\beta}\)</span>, which we denote as <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. The latter contains the estimated effects of the included covariates (e.g. proportion of solid tissue). To obtain a risk estimate for patient <span class="math inline">\(i\)</span>, we multiply the covariate vector <span class="math inline">\(\boldsymbol{x}_i\)</span> (which contains all the patient-specific characteristics) with the estimated parameter vector <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> to obtain the linear predictor <span class="math inline">\(\widehat{\eta}_i\)</span>
<span class="math display">\[\begin{align*}
  \widehat{\eta}_i = \boldsymbol{x}_i^\top \widehat{\boldsymbol{\beta}}.
\end{align*}\]</span></p>
<p>To differentiate between the training and test set, we append the subscript <span class="math inline">\(*\)</span> to the quantities of the test set. Hence, <span class="math inline">\({}_{*} y_i\)</span> denotes the outcome in the test set. Similarly, we use <span class="math inline">\({}_{*} \boldsymbol{x}_i\)</span> to denote the covariate vector for patient <span class="math inline">\(i\)</span> in the test set. We then calculate the linear predictor on the test set as
<span class="math display">\[\begin{align*}
  {}_{*} \widehat{\eta}_i = {}_{*} \boldsymbol{x}_i^\top \widehat{\boldsymbol{\beta}} \tag{1}.
\end{align*}\]</span></p>
<p>Similarly, we can predict the probability <span class="math inline">\(\widehat{f}({}_{*} \boldsymbol{x}_i)\)</span> for patient <span class="math inline">\(i\)</span> in the test set using machine learning methods. We use
<span class="math display">\[\begin{align*}
  {}_{*} \widehat{\pi}_i = \widehat{f}({}_{*} \boldsymbol{x}_i)
\end{align*}\]</span>
as a general notation to denote the predicted probability of the risk prediction model.</p>
<p>One way to compute the calibration curve, is by using a logistic regression model
<span class="math display" id="eq:logcal">\[\begin{align*}
  \text{logit}(P({}_{*} y_i = 1| {}_{*} \widehat{\pi}_i)) &amp;= \alpha + \zeta \ \text{logit}({}_{*} \widehat{\pi}_i)
  \tag{1.1}
\end{align*}\]</span>
where we estimate the observed proportions as a function of the predicted probabilities. This model fit yields a logistic calibration curve. Note that <span class="math inline">\(\text{logit}({}_{*} \widehat{\pi}_i) = {}_{*} \widehat{\eta}_i\)</span> when <span class="math inline">\({}_{*} \widehat{\pi}_i\)</span> is estimated using a logistic regression model (see <a href="#eq:logcal">(1.1)</a>).</p>
<p>Alternatively, we can obtain flexible, nonlinear calibration curve using a non-parametric smoother such as loess or restricted cubic splines. In our package, we provide both types of calibration curves.</p>
</div>
<div class="section level4" number="1.3.4">
<h4 id="calibration-intercept-and-slope">
<span class="header-section-number">1.3.4</span> Calibration intercept and slope<a class="anchor" aria-label="anchor" href="#calibration-intercept-and-slope"></a>
</h4>
<p>In addition to the calibration curve, we have two measures that summarize different aspects of the calibration performance:</p>
<ul>
<li>the calibration intercept <span class="math inline">\(\alpha_c\)</span> (calibration-in-the-large);</li>
<li>the calibration slope <span class="math inline">\(\zeta\)</span>.</li>
</ul>
<p>We have a perfectly calibrated model when the calibration curve coincides with the diagonal line or when <span class="math inline">\(\alpha =\alpha_c = 0\)</span> and <span class="math inline">\(\zeta = 1\)</span>.</p>
<p>To compute the calibration slope <span class="math inline">\(\zeta\)</span>, we rely on the model used to obtain the logistic calibration curve (see equation <a href="#eq:logcal">(1.1)</a>). The value of the calibration slope <span class="math inline">\(\zeta\)</span> tells us whether the model is over- or underfitted. When <span class="math inline">\(\zeta &lt; 1\)</span> the model is overfitted. <span class="math inline">\(\zeta &lt; 1\)</span> indicates that <span class="math inline">\({}_{*} \eta_i\)</span> is too extreme and needs to be lower to ensure that the predicted risks coincide with the observed risks. Conversely, we have a model that is underfitted when <span class="math inline">\(\zeta &gt; 1\)</span>.</p>
<p>To calculate the calibration intercept or calibration-in-the-large, we fix the calibration slope at <span class="math inline">\(1\)</span> and denote this as <span class="math inline">\(\alpha|\zeta = 1\)</span> or the short-hand notation <span class="math inline">\(\alpha_c\)</span>. To estimate <span class="math inline">\(\alpha_c\)</span>, we fit the model
<span class="math display" id="eq:calintercept">\[\begin{align*}
  \text{logit}(P({}_{*} y_i = 1| {}_{*} \widehat{\pi}_i)) &amp;= \alpha_c + \text{offset}(\text{logit}({}_{*} \widehat{\pi}_i))
  \tag{1.2}
\end{align*}\]</span>
where we enter <span class="math inline">\(\text{logit}({}_{*} \widehat{\pi}_i)\)</span> as an offset variable. Hereby, we fix <span class="math inline">\(\zeta = 1\)</span>. The calibration intercept tells us whether the risks are overestimated <span class="math inline">\((\alpha_c &lt; 0)\)</span> or underestimated <span class="math inline">\((\alpha_c &gt; 0)\)</span> <strong>on average</strong>.</p>
</div>
</div>
<div class="section level3" number="1.4">
<h3 id="illustration-of-the-calibrationcurves-package">
<span class="header-section-number">1.4</span> Illustration of the CalibrationCurves package<a class="anchor" aria-label="anchor" href="#illustration-of-the-calibrationcurves-package"></a>
</h3>
<div class="section level4" number="1.4.1">
<h4 id="training-the-model">
<span class="header-section-number">1.4.1</span> Training the model<a class="anchor" aria-label="anchor" href="#training-the-model"></a>
</h4>
<p>To illustrate the functionality, the package has two example data sets: <code>traindata</code> and <code>testdata</code>. These are two synthetically generated data sets (using the same underlying process/settings to generate the data) to illustrate the functionality of the <code>CalibrationCurves</code> package.</p>
<p>The <code>traindata</code> data frame represents the data that we will use to develop our risk prediction model</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://bavodc.github.io/websiteCalibrationCurves/" class="external-link">CalibrationCurves</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: rms</span></span>
<span><span class="co">#&gt; Loading required package: Hmisc</span></span>
<span><span class="co">#&gt; Warning: package 'Hmisc' was built under R version 4.4.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'Hmisc'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     format.pval, units</span></span>
<span><span class="co">#&gt; Loading required package: ggplot2</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"traindata"</span><span class="op">)</span></span></code></pre></div>
<p>In this data frame, we have four covariates and one response variable <code>y</code>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">traindata</span><span class="op">)</span></span>
<span><span class="co">#&gt;   y          x1         x2         x3         x4</span></span>
<span><span class="co">#&gt; 1 0 -0.19981624  0.2982990  1.0277486 -0.1146414</span></span>
<span><span class="co">#&gt; 2 1 -1.37127488  0.5940002 -0.8234645  2.0927676</span></span>
<span><span class="co">#&gt; 3 1  1.04050541  0.5440481 -1.3576457  1.3126813</span></span>
<span><span class="co">#&gt; 4 0 -1.11652476 -0.5382577 -1.1651439  1.0987873</span></span>
<span><span class="co">#&gt; 5 1  1.39659613  1.1325081  0.6053029 -1.0598506</span></span>
<span><span class="co">#&gt; 6 0 -0.04645095 -0.8167364  1.0196761 -0.4867560</span></span></code></pre></div>
<p>Next, we fit a logistic regression model to obtain the estimated parameter vector <span class="math inline">\(\widehat{\beta}\)</span>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glmFit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span> , data <span class="op">=</span> <span class="va">traindata</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">glmFit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = y ~ ., family = binomial, data = traindata)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  0.08915    0.08016   1.112    0.266    </span></span>
<span><span class="co">#&gt; x1           0.60585    0.08475   7.148 8.79e-13 ***</span></span>
<span><span class="co">#&gt; x2           1.38035    0.10554  13.079  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; x3          -0.75109    0.08854  -8.483  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; x4           0.82757    0.08759   9.448  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 1385.89  on 999  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance:  950.28  on 995  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 960.28</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></span></code></pre></div>
</div>
<div class="section level4" number="1.4.2">
<h4 id="assessing-the-calibration-performance">
<span class="header-section-number">1.4.2</span> Assessing the calibration performance<a class="anchor" aria-label="anchor" href="#assessing-the-calibration-performance"></a>
</h4>
<p>Hereafter, we assess the calibration performance on the <code>testdata</code> set. Hereto, we first have to compute the predicted probabilities on this data set.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"testdata"</span><span class="op">)</span></span>
<span><span class="va">pHat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">glmFit</span>, newdata <span class="op">=</span> <span class="va">testdata</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span></code></pre></div>
<p>We then store the response in the <code>testdata</code> in a separate vector <code>yTest</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yTest</span> <span class="op">=</span> <span class="va">testdata</span><span class="op">$</span><span class="va">y</span></span></code></pre></div>
<p>Now we have everything we need to assess the calibration performance of our prediction model. We can either use <code>val.prob.ci.2</code> or <code>valProbggplot</code> to visualize the calibration performance and to obtain the statistics. <code>val.prob.ci.2</code> makes the plot using <code>base</code> R and <code>valProbggplot</code> uses the <code>ggplot2</code> package.</p>
<p>By default, the flexible calibration curve (based on a loess smoother) will be plotted.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">calPerf</span> <span class="op">=</span> <span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-6-1.png" width="100%">
In addition to the plot, the function returns an object of the class <code>CalibrationCurve</code>.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">calPerf</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; val.prob.ci.2(p = pHat, y = yTest)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic. </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p </span></span>
<span><span class="co">#&gt;   0.62853462   0.81426731   0.38019823   0.33282644 167.41322219   0.00000000 </span></span>
<span><span class="co">#&gt;            U     U:Chi-sq          U:p            Q        Brier    Intercept </span></span>
<span><span class="co">#&gt;   0.01286390   8.43195136   0.01475792   0.31996254   0.17703339   0.22404680 </span></span>
<span><span class="co">#&gt;        Slope         Emax Brier scaled         Eavg          ECI </span></span>
<span><span class="co">#&gt;   0.82278297   0.08288689   0.28730517   0.04747448   0.32064056</span></span></code></pre></div>
<p>This object contains the calculated statistics as well as the calculated coordinates of the calibration curve.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">calPerf</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 7</span></span>
<span><span class="co">#&gt;  $ call             : language val.prob.ci.2(p = pHat, y = yTest)</span></span>
<span><span class="co">#&gt;  $ stats            : Named num [1:17] 0.629 0.814 0.38 0.333 167.413 ...</span></span>
<span><span class="co">#&gt;   ..- attr(*, "names")= chr [1:17] "Dxy" "C (ROC)" "R2" "D" ...</span></span>
<span><span class="co">#&gt;  $ cl.level         : num 0.95</span></span>
<span><span class="co">#&gt;  $ Calibration      :List of 2</span></span>
<span><span class="co">#&gt;   ..$ Intercept: Named num [1:3] 0.22405 0.00339 0.4447</span></span>
<span><span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:3] "Point estimate" "Lower confidence limit" "Upper confidence limit"</span></span>
<span><span class="co">#&gt;   ..$ Slope    : Named num [1:3] 0.823 0.666 0.98</span></span>
<span><span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:3] "Point estimate" "Lower confidence limit.2.5 %" "Upper confidence limit.97.5 %"</span></span>
<span><span class="co">#&gt;  $ Cindex           : Named num [1:3] 0.814 0.774 0.848</span></span>
<span><span class="co">#&gt;   ..- attr(*, "names")= chr [1:3] "Point estimate" "Lower confidence limit" "Upper confidence limit"</span></span>
<span><span class="co">#&gt;  $ warningMessages  : NULL</span></span>
<span><span class="co">#&gt;  $ CalibrationCurves:List of 1</span></span>
<span><span class="co">#&gt;   ..$ FlexibleCalibration:'data.frame':  500 obs. of  4 variables:</span></span>
<span><span class="co">#&gt;   .. ..$ x   : num [1:500] 0.00561 0.00651 0.00706 0.01183 0.01235 ...</span></span>
<span><span class="co">#&gt;   .. ..$ y   : num [1:500] 0.0504 0.0514 0.052 0.0572 0.0578 ...</span></span>
<span><span class="co">#&gt;   .. ..$ ymin: num [1:500] 0 0 0 0 0 0 0 0 0 0 ...</span></span>
<span><span class="co">#&gt;   .. ..$ ymax: num [1:500] 0.177 0.177 0.177 0.179 0.179 ...</span></span>
<span><span class="co">#&gt;  - attr(*, "class")= chr "CalibrationCurve"</span></span></code></pre></div>
<p>The coordinates are stored in the <code>CalibrationCurves</code> slot and can be extracted as follows.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flexCal</span> <span class="op">=</span> <span class="va">calPerf</span><span class="op">$</span><span class="va">CalibrationCurves</span><span class="op">$</span><span class="va">FlexibleCalibration</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">flexCal</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, type <span class="op">=</span> <span class="st">"l"</span>, xlab <span class="op">=</span> <span class="st">"Predicted probability"</span>, ylab <span class="op">=</span> <span class="st">"Observed proportion"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, xlim <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, ylim <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html" class="external-link">polygon</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">flexCal</span><span class="op">$</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">flexCal</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="va">flexCal</span><span class="op">$</span><span class="va">ymax</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="va">flexCal</span><span class="op">$</span><span class="va">ymin</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/rgb.html" class="external-link">rgb</a></span><span class="op">(</span><span class="fl">177</span>, <span class="fl">177</span>, <span class="fl">177</span>, <span class="fl">177</span>, maxColorValue <span class="op">=</span> <span class="fl">255</span><span class="op">)</span>,</span>
<span>  border <span class="op">=</span> <span class="cn">NA</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-9-1.png" width="672"></p>
<p>Alternatively, we can use restricted cubic splines to obtain the flexible calibration curve.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rcsFit</span> <span class="op">=</span> <span class="kw"><a href="https://rdrr.io/r/base/conditions.html" class="external-link">tryCatch</a></span><span class="op">(</span><span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, smooth <span class="op">=</span> <span class="st">"rcs"</span><span class="op">)</span>,</span>
<span>                  error <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/rcsFit-1.png" width="100%"></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">if</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/logical.html" class="external-link">is.logical</a></span><span class="op">(</span><span class="va">rcsFit</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fl">1</span>, type <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">""</span>, ylab <span class="op">=</span> <span class="st">""</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">5</span>, y <span class="op">=</span> <span class="fl">5</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"There was a problem estimating\n"</span>,</span>
<span>                                     <span class="st">"the calibration curve using rcs"</span><span class="op">)</span>, cex <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>  <span class="va">rcsFit</span></span>
<span><span class="op">}</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; val.prob.ci.2(p = pHat, y = yTest, smooth = "rcs")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic. </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p </span></span>
<span><span class="co">#&gt;   0.62853462   0.81426731   0.38019823   0.33282644 167.41322219   0.00000000 </span></span>
<span><span class="co">#&gt;            U     U:Chi-sq          U:p            Q        Brier    Intercept </span></span>
<span><span class="co">#&gt;   0.01286390   8.43195136   0.01475792   0.31996254   0.17703339   0.22404680 </span></span>
<span><span class="co">#&gt;        Slope         Emax Brier scaled </span></span>
<span><span class="co">#&gt;   0.82278297   0.08288689   0.28730517</span></span></code></pre></div>
<p>We obtain the logistic calibration curve using the following code.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, logistic.cal <span class="op">=</span> <span class="cn">TRUE</span>, smooth <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-10-1.png" width="100%"></p>
<p>We can plot both using</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, logistic.cal <span class="op">=</span> <span class="cn">TRUE</span>, col.log <span class="op">=</span> <span class="st">"orange"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-11-1.png" width="100%"></p>
<p>The package also allows to change the colors, change the position of the legend and much more. Check out the help-function to see what other arguments the functions have.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, col.ideal <span class="op">=</span> <span class="st">"black"</span>, col.smooth <span class="op">=</span> <span class="st">"red"</span>, CL.smooth <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>              legendloc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, statloc <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.25</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-12-1.png" width="100%"></p>
<p>Finally, we can also decide which statistics appear on the plot.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, dostats <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"C (ROC)"</span>, <span class="st">"Intercept"</span>, <span class="st">"Slope"</span>, <span class="st">"ECI"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-13-1.png" width="100%"></p>
</div>
<div class="section level4" number="1.4.3">
<h4 id="ggplot-version">
<span class="header-section-number">1.4.3</span> ggplot version<a class="anchor" aria-label="anchor" href="#ggplot-version"></a>
</h4>
<p>The ggplot version (i.e.<code>valProbggplot</code>) uses virtually the same arguments. Hence, we can easily obtain a ggplot using the same code.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/valProbggplot.html">valProbggplot</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-14-1.png" width="100%"></p>
<pre><code><span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; valProbggplot(p = pHat, y = yTest)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; A 95% confidence interval is given for the calibration intercept, calibration slope and c-statistic. </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;          Dxy      C (ROC)           R2            D     D:Chi-sq          D:p </span></span>
<span><span class="co">#&gt;   0.62853462   0.81426731   0.38019823   0.33282644 167.41322219   0.00000000 </span></span>
<span><span class="co">#&gt;            U     U:Chi-sq          U:p            Q        Brier    Intercept </span></span>
<span><span class="co">#&gt;   0.01286390   8.43195136   0.01475792   0.31996254   0.17703339   0.22404680 </span></span>
<span><span class="co">#&gt;        Slope         Emax Brier scaled         Eavg          ECI </span></span>
<span><span class="co">#&gt;   0.82278297   0.08288689   0.28730517   0.04747448   0.32064056</span></span></code></pre>
</div>
</div>
</div>
<div class="section level2" number="2">
<h2 id="assessing-the-performance-of-survival-models">
<span class="header-section-number">2</span> Assessing the performance of survival models<a class="anchor" aria-label="anchor" href="#assessing-the-performance-of-survival-models"></a>
</h2>
<div class="section level3" number="2.1">
<h3 id="cox-proportional-hazards-model">
<span class="header-section-number">2.1</span> Cox Proportional hazards model<a class="anchor" aria-label="anchor" href="#cox-proportional-hazards-model"></a>
</h3>
<p>The Cox proportional hazards model is a widely used method for analyzing survival data. It estimates the hazard function, which represents the instantaneous risk of an event occurring at time <span class="math inline">\(t\)</span>, given that the subject has survived up to <span class="math inline">\(t\)</span>. For patient <span class="math inline">\(i\)</span> with covariate vector <span class="math inline">\(\boldsymbol{x}_i\)</span>, the hazard function is given by:</p>
<p><span class="math display">\[\begin{align*}
  h(t | \boldsymbol{x}_i) &amp;= h_0(t) \exp(\boldsymbol{x}_i^\top \beta)\\
  &amp;= h_0(t) \exp(\eta_i)
\end{align*}\]</span></p>
<p>where</p>
<ul>
<li>
<span class="math inline">\(h(t | \boldsymbol{x}_i)\)</span> is the hazard function at time <span class="math inline">\(t\)</span> for subject <span class="math inline">\(i\)</span>,</li>
<li>
<span class="math inline">\(h_0(t)\)</span> is the baseline hazard function at time <span class="math inline">\(t\)</span>, which is shared by all individuals.</li>
</ul>
<p>In this model, the survival probability for an individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span> is given by</p>
<p><span class="math display">\[
S_i(t) = \exp\left(-H_i(t)\right)
\]</span></p>
<p>where <span class="math inline">\(H_i(t)\)</span> is the cumulative hazard function:</p>
<p><span class="math display">\[
H_i(t) = H_0(t) \exp( \eta_i)
\]</span></p>
<p>where <span class="math inline">\(H_0(t)\)</span> is the <strong>baseline cumulative hazard function</strong>.</p>
<div class="section level4" number="2.1.1">
<h4 id="calibration-curve">
<span class="header-section-number">2.1.1</span> Calibration Curve<a class="anchor" aria-label="anchor" href="#calibration-curve"></a>
</h4>
<p>We can estimate the calibration curve in this scenario by entering the linear predictor <span class="math inline">\(\eta_i\)</span> as a covariate<br><span class="math display">\[\begin{align*}
  h(t | {}_{*} \eta_i) &amp;= h_0(t) \exp(\zeta {}_{*} \eta_i)\\
\end{align*}\]</span>
where <span class="math inline">\(\zeta\)</span> is the calibration slope that quantifies the relationship between the predicted and observed hazards. Similarly to <a href="#eq:logcal">(1.1)</a>, <span class="math inline">\(\zeta\)</span> indicates whether the model is over- (<span class="math inline">\(\zeta &lt; 1\)</span>) or underfitted (<span class="math inline">\(\zeta &gt;1\)</span>). Note that we do not have a calibration intercept in this model. This is because the baseline hazard function <span class="math inline">\(h_0(t)\)</span> is not estimated in the Cox model, and the model is only identified up to a proportionality constant. As a result, any intercept term would be absorbed into the baseline hazard function, and would not be separately identifiable.</p>
<p>We do not explicitly specify the time point <span class="math inline">\(t\)</span>, as calibration can be assessed either across all follow-up time points or at a specific time point of interest. To estimate this model, we can fit a Cox proportional hazards model.</p>
<p>Below is a short example how you can assess the calibration performance using the package.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">trainDataSurvival</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">testDataSurvival</span><span class="op">)</span></span>
<span><span class="va">sFit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/survival/man/coxph.html" class="external-link">coxph</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html" class="external-link">Surv</a></span><span class="op">(</span><span class="va">ryear</span>, <span class="va">rfs</span><span class="op">)</span> <span class="op">~</span> <span class="va">csize</span> <span class="op">+</span> <span class="va">cnode</span> <span class="op">+</span> <span class="va">grade3</span>, data <span class="op">=</span> <span class="va">trainDataSurvival</span>,</span>
<span>             x <span class="op">=</span> <span class="cn">TRUE</span>, y <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">calPerf</span> <span class="op">=</span> <span class="fu"><a href="../reference/valProbSurvival.html">valProbSurvival</a></span><span class="op">(</span><span class="va">sFit</span>, <span class="va">testDataSurvival</span>, plotCal <span class="op">=</span> <span class="st">"ggplot"</span>, nk <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-15-1.png" width="672"></p>
<p>Next to the plot, you also get a range of statistics regarding the calibration performance.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">calPerf</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; valProbSurvival(fit = sFit, valdata = testDataSurvival, nk = 5, </span></span>
<span><span class="co">#&gt;     plotCal = "ggplot")</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; A 95% confidence interval is given for the statistics. </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Calibration performance:</span></span>
<span><span class="co">#&gt; ------------------------</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; In the large</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        OE     2.5 %    97.5 % </span></span>
<span><span class="co">#&gt; 1.0444489 0.9299645 1.1730270 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Slope</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; calibration slope             2.5 %            97.5 % </span></span>
<span><span class="co">#&gt;         1.0703257         0.8202242         1.3204271 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Additional statistics</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        ICI        E50        E90       Emax </span></span>
<span><span class="co">#&gt; 0.02844123 0.04046305 0.05838470 0.05857903 </span></span>
<span><span class="co">#&gt;         model times     Brier           se     lower     upper       IPA</span></span>
<span><span class="co">#&gt;        &lt;fctr&gt; &lt;num&gt;     &lt;num&gt;        &lt;num&gt;     &lt;num&gt;     &lt;num&gt;     &lt;num&gt;</span></span>
<span><span class="co">#&gt; 1: Null model  4.99 0.2499302 0.0004004949 0.2491452 0.2507151 0.0000000</span></span>
<span><span class="co">#&gt; 2:        cox  4.99 0.2245471 0.0077937209 0.2092717 0.2398225 0.1015608</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Discrimination performance:</span></span>
<span><span class="co">#&gt; -------------------------------</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Concordance statistic</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            Estimate     2.5 %    97.5 %</span></span>
<span><span class="co">#&gt; Harrell C 0.6517240 0.6193261 0.6841220</span></span>
<span><span class="co">#&gt; Uno C     0.6388712 0.6071328 0.6706096</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Time-dependent AUC</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   Uno AUC     2.5 %   97. 5 % </span></span>
<span><span class="co">#&gt; 0.6856354 0.6305826 0.7406882</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level2" number="3">
<h2 id="assessing-the-performance-of-other-types-of-prediction-models">
<span class="header-section-number">3</span> Assessing the performance of other types of prediction models<a class="anchor" aria-label="anchor" href="#assessing-the-performance-of-other-types-of-prediction-models"></a>
</h2>
<p>In my recent paper <span class="citation">(De Cock Campo 2023)</span>, I propose an extension of the logistic calibration framework to distributions that belong to the exponential family with probability density function (pdf)
<span class="math display">\[\begin{align*}
        f(y_i; \theta_i, \phi, w_i) = \exp\left( \frac{y_i \theta_i - b(\theta_i)}{\phi} w_i  + c(y_i, \phi, w_i)\right).
\end{align*}\]</span></p>
<p>
Here, <span class="math inline">\(\theta_i\)</span> is the natural parameter, <span class="math inline">\(\phi\)</span> the dispersion parameter and <span class="math inline">\(w_i\)</span> the weight. <span class="math inline">\(b(\cdot)\)</span> and <span class="math inline">\(c(\cdot)\)</span> are known functions. Similar to before, we assume that there is an unknown regression function <span class="math inline">\(r(\boldsymbol{x}_i) = E[y_i | \boldsymbol{x}_i]\)</span>. To approximate this unknown function, we rely on prediction models with the following functional form
<span class="math display" id="eq:PredModel">\[\begin{align*}
    E[y_i | \boldsymbol{x}_i] = \mu_i = f(\boldsymbol{x}_i).
    \tag{3.1}
\end{align*}\]</span></p>
<p>
To estimate <a href="#eq:PredModel">(3.1)</a>, we can use a generalized linear model
<span class="math display" id="eq:GLM">\[\begin{align*}
        g(E[y_i | \boldsymbol{x}_i]) = \boldsymbol{x}_i^\top \boldsymbol{\beta} = \eta_i.
        \tag{3.2}
\end{align*}\]</span>
where <span class="math inline">\(g(\cdot)\)</span> denotes the link function. Alternatively, we can estimate <a href="#eq:PredModel">(3.1)</a> using machine learning methods. Using the model fit, we obtain the predictions <span class="math inline">\(\widehat{\mu}_i = \widehat{f}(\boldsymbol{x}_i)\)</span>.</p>
<div class="section level3" number="3.1">
<h3 id="generalized-calibration-curves">
<span class="header-section-number">3.1</span> Generalized calibration curves<a class="anchor" aria-label="anchor" href="#generalized-calibration-curves"></a>
</h3>
<p>To examine the calibration of prediction models where the outcome is a member of the exponential family, we redefine the framework in more general terms. In this context, a calibration curve maps the predicted values <span class="math inline">\(f(\boldsymbol{x}_i)\)</span> to <span class="math inline">\(E[y_i| f(\boldsymbol{x}_i)]\)</span>, the actual conditional mean of <span class="math inline">\(y_i\)</span> given <span class="math inline">\(f(\boldsymbol{x}_i)\)</span>. As before, a model is perfectly calibrated if the calibration curve equals the diagonal, i.e. <span class="math inline">\(E[y_i | f(\boldsymbol{x}_i)] = f(\boldsymbol{x}_i) \ \forall \ i\)</span>. Hence, in this context, the calibration curve captures the correspondence between the predicted values and the conditional mean.</p>
<p>We propose two methods to estimate the calibration curve. Firstly, we can estimate the calibration curve using a generalized linear model
<span class="math display" id="eq:CalibrationGLM">\[\begin{align*}
        g(E[{}_{*} y_i | {}_{*} \widehat{\mu}_i]) = \alpha + \zeta \ g({}_{*} \widehat{\mu}_i).
        \tag{3.3}
\end{align*}\]</span></p>
<p>By transforming <span class="math inline">\({}_{*} \widehat{\mu}_i\)</span> using the appropriate <span class="math inline">\(g(\cdot)\)</span>, we map <span class="math inline">\({}_{*} \widehat{\mu}_i\)</span> to the whole real line to better fit the model. If <span class="math inline">\({}_{*} \widehat{\mu}_i\)</span> is estimated using a generalized linear model with the same link function (i.e. <span class="math inline">\(g(\cdot)\)</span> is identical in <a href="#eq:GLM">(3.2)</a> and <a href="#eq:CalibrationGLM">(3.3)</a>), it follows that <span class="math inline">\(g({}_{*} \widehat{\mu}_i) = {}_{*} \widehat{\eta}_i\)</span>. Using equation <a href="#eq:CalibrationGLM">(3.3)</a>, we estimate the empirical average as a function of the predicted values. Further, similarly to <a href="#eq:logcal">(1.1)</a>, <span class="math inline">\(\zeta\)</span> tells us whether the model is over- (<span class="math inline">\(\zeta &lt; 1\)</span>) or underfitted (<span class="math inline">\(\zeta &gt;1\)</span>). We estimate the calibration-in-the-large <span class="math inline">\(\alpha_c\)</span> as
<span class="math display" id="eq:CITLGLM">\[\begin{align*}
        g(E[{}_{*} y_i | {}_{*} \widehat{\mu}_i]) = \alpha_c + \text{offset}(g({}_{*} \widehat{\mu}_i)).
        \tag{3.4}
\end{align*}\]</span>
Hereby, we assess to which extent the observed empirical average equals the average predicted value. Secondly, as with the logistic regression model, we can employ non-parametric smoothers to estimate the calibration curve.</p>
</div>
<div class="section level3" number="3.2">
<h3 id="illustration-of-the-generalized-calibration-framework">
<span class="header-section-number">3.2</span> Illustration of the generalized calibration framework<a class="anchor" aria-label="anchor" href="#illustration-of-the-generalized-calibration-framework"></a>
</h3>
<div class="section level4" number="3.2.1">
<h4 id="training-the-model-1">
<span class="header-section-number">3.2.1</span> Training the model<a class="anchor" aria-label="anchor" href="#training-the-model-1"></a>
</h4>
<p>To illustrate the functionality, the package has two example data sets with a poisson distributed outcome variable: <code>poissontraindata</code> and <code>poissontestdata</code>. These are two synthetically generated data sets (using the same underlying process/settings to generate the data) to illustrate the functionality of the <code>CalibrationCurves</code> package.</p>
<p>The <code>poissontraindata</code> data frame represents the data that we will use to develop our prediction model.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"poissontraindata"</span><span class="op">)</span></span></code></pre></div>
<p>In this data frame, we have five covariates and one response variable <code>y</code>.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">traindata</span><span class="op">)</span></span>
<span><span class="co">#&gt;   y          x1         x2         x3         x4</span></span>
<span><span class="co">#&gt; 1 0 -0.19981624  0.2982990  1.0277486 -0.1146414</span></span>
<span><span class="co">#&gt; 2 1 -1.37127488  0.5940002 -0.8234645  2.0927676</span></span>
<span><span class="co">#&gt; 3 1  1.04050541  0.5440481 -1.3576457  1.3126813</span></span>
<span><span class="co">#&gt; 4 0 -1.11652476 -0.5382577 -1.1651439  1.0987873</span></span>
<span><span class="co">#&gt; 5 1  1.39659613  1.1325081  0.6053029 -1.0598506</span></span>
<span><span class="co">#&gt; 6 0 -0.04645095 -0.8167364  1.0196761 -0.4867560</span></span></code></pre></div>
<p>Next, we fit a Poisson GLM with log link to obtain the estimated parameter vector <span class="math inline">\(\widehat{\beta}\)</span>.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">glmFit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span> , data <span class="op">=</span> <span class="va">poissontraindata</span>, family <span class="op">=</span> <span class="va">poisson</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">glmFit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = Y ~ ., family = poisson, data = poissontraindata)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept) -2.33425    0.05301 -44.034  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; x1           1.28147    0.17645   7.262 3.80e-13 ***</span></span>
<span><span class="co">#&gt; x2           2.02783    0.18019  11.254  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; x3          -1.16815    0.16907  -6.909 4.88e-12 ***</span></span>
<span><span class="co">#&gt; x4          -1.88795    0.17840 -10.583  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; x5          -1.84003    0.17866 -10.299  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 3087.4  on 4999  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 2660.4  on 4994  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 4053.3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 6</span></span></code></pre></div>
</div>
<div class="section level4" number="3.2.2">
<h4 id="assessing-the-calibration-performance-1">
<span class="header-section-number">3.2.2</span> Assessing the calibration performance<a class="anchor" aria-label="anchor" href="#assessing-the-calibration-performance-1"></a>
</h4>
<p>Hereafter, we assess the calibration performance on the <code>poissontestdata</code> set. Hereto, we first have to compute the predicted values on this data set.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"poissontestdata"</span><span class="op">)</span></span>
<span><span class="va">yHat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">glmFit</span>, newdata <span class="op">=</span> <span class="va">poissontestdata</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span></code></pre></div>
<p>We then store the response in the <code>poissontestdata</code> in a separate vector <code>yTest</code>.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yTest</span> <span class="op">=</span> <span class="va">poissontestdata</span><span class="op">$</span><span class="va">Y</span></span></code></pre></div>
<p>Now we have everything we need to assess the calibration performance of our prediction model. We can use <code>genCalCurve</code> to visualize the calibration performance and to obtain the statistics. <code>genCalCurve</code> makes the plot using <code>base</code> R and a ggplot version will be included in one of the next updates.</p>
<p>By default, the calibration curve as estimated by a GLM will be plotted. Further, in addition to the outcome and the predicted values, we have to specify the distribution of the response variable.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">calPerf</span> <span class="op">=</span> <span class="fu"><a href="../reference/genCalCurve.html">genCalCurve</a></span><span class="op">(</span><span class="va">yTest</span>, <span class="va">yHat</span>, family <span class="op">=</span> <span class="va">poisson</span><span class="op">)</span></span>
<span><span class="co">#&gt; Waiting for profiling to be done...</span></span>
<span><span class="co">#&gt; Waiting for profiling to be done...</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-22-1.png" width="100%">
In addition to the plot, the function returns an object of the class <code>GeneralizedCalibrationCurve</code>.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">calPerf</span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; genCalCurve(y = yTest, yHat = yHat, family = poisson)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; A 95% confidence interval is given for the calibration intercept and calibration slope. </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Calibration intercept     Calibration slope </span></span>
<span><span class="co">#&gt;            0.02710876            0.98320991</span></span></code></pre></div>
<p>This object contains the calculated statistics as well as the calculated coordinates of the calibration curve.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">calPerf</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 6</span></span>
<span><span class="co">#&gt;  $ call             : language genCalCurve(y = yTest, yHat = yHat, family = poisson)</span></span>
<span><span class="co">#&gt;  $ stats            : Named num [1:2] 0.0271 0.9832</span></span>
<span><span class="co">#&gt;   ..- attr(*, "names")= chr [1:2] "Calibration intercept" "Calibration slope"</span></span>
<span><span class="co">#&gt;  $ cl.level         : num 0.95</span></span>
<span><span class="co">#&gt;  $ Calibration      :List of 2</span></span>
<span><span class="co">#&gt;   ..$ Intercept: Named num [1:3] 0.0271 -0.1368 0.1825</span></span>
<span><span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:3] "Point estimate.Calibration intercept" "Lower confidence limit.2.5 %" "Upper confidence limit.97.5 %"</span></span>
<span><span class="co">#&gt;   ..$ Slope    : Named num [1:3] 0.983 0.768 1.198</span></span>
<span><span class="co">#&gt;   .. ..- attr(*, "names")= chr [1:3] "Point estimate.Calibration slope" "Lower confidence limit.2.5 %" "Upper confidence limit.97.5 %"</span></span>
<span><span class="co">#&gt;  $ warningMessages  : NULL</span></span>
<span><span class="co">#&gt;  $ CalibrationCurves:List of 1</span></span>
<span><span class="co">#&gt;   ..$ GLMCalibration:'data.frame':   1000 obs. of  2 variables:</span></span>
<span><span class="co">#&gt;   .. ..$ x: num [1:1000] 0.0111 0.012 0.0124 0.0142 0.0149 ...</span></span>
<span><span class="co">#&gt;   .. ..$ y: num [1:1000] 0.012 0.013 0.0134 0.0152 0.0159 ...</span></span>
<span><span class="co">#&gt;  - attr(*, "class")= chr "GeneralizedCalibrationCurve"</span></span></code></pre></div>
<p>The coordinates are stored in the <code>CalibrationCurves</code> slot and can be extracted as follows.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">GLMCal</span> <span class="op">=</span> <span class="va">calPerf</span><span class="op">$</span><span class="va">CalibrationCurves</span><span class="op">$</span><span class="va">GLMCalibration</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">GLMCal</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, type <span class="op">=</span> <span class="st">"l"</span>, xlab <span class="op">=</span> <span class="st">"Predicted value"</span>, ylab <span class="op">=</span> <span class="st">"Empirical average"</span>, lwd <span class="op">=</span> <span class="fl">2</span>, xlim <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, ylim <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>,</span>
<span>     col <span class="op">=</span> <span class="st">"red"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-25-1.png" width="672"></p>
</div>
</div>
</div>
<div class="section level2" number="4">
<h2 id="faq">
<span class="header-section-number">4</span> FAQ<a class="anchor" aria-label="anchor" href="#faq"></a>
</h2>
<div class="section level3" number="4.1">
<h3 id="why-is-the-calibration-intercept-different-in-the-rms-package">
<span class="header-section-number">4.1</span> Why is the calibration intercept different in the rms package?<a class="anchor" aria-label="anchor" href="#why-is-the-calibration-intercept-different-in-the-rms-package"></a>
</h3>
<p>To construct the logistic calibration curve (see <a href="#how-do-we-construct-a-calibration-curve">How do we construct a calibration curve?</a>), we fit the model
<span class="math display">\[\begin{align*}
\text{logit}(E[{}_{*} y_i | {}_{*} \widehat{\pi}_i]) = \alpha + \zeta \ \text{logit}({}_{*} \widehat{\pi}_i)
\end{align*}\]</span>
Here, <span class="math inline">\(\zeta\)</span> corresponds to the calibration slope. The calibration intercept from the <code>val.prob</code> function from the <code>rms</code> package corresponds to <span class="math inline">\(\alpha \neq \alpha_c\)</span>.</p>
<p>In the <code>CalibrationCurves</code> package, the calibration intercept corresponds to <span class="math inline">\(\alpha_c\)</span> which assesses the calibration in the large. Using this formulation, the calibration intercept indicates whether the predicted risks are under- or overestimated on average and this is conform with the definition of the calibration intercept in the article ‘A calibration hierarchy for risk models was defined: from utopia to empirical data’ (and other articles published on this topic) <span class="citation">(Van Calster et al. 2016, 2019)</span>. We compute <span class="math inline">\(\alpha_c\)</span> using
<span class="math display">\[\begin{align*}
\text{logit}(E[{}_{*} y_i | {}_{*} \widehat{\pi}_i]) = \alpha_c + \text{offset}(\text{logit}({}_{*} \widehat{\pi}_i)).
\end{align*}\]</span>
where we fix <span class="math inline">\(\zeta = 1\)</span> by including <span class="math inline">\(\text{logit}({}_{*} \widehat{\pi}_i)\)</span> as an offset variable.</p>
<p>Consequently, both types of calibration intercepts need to be interpreted differently:</p>
<ul>
<li>
<span class="math inline">\(\alpha\)</span>:
<ul>
<li>this corresponds to the constant you have to add after you multiplied the linear predictor with the ‘correction’ factor (i.e. the calibration slope) to get the predicted probabilities to correspond to the observed ones. In essence: once we have multiplied the linear predictor by a correction factor, what is the constant that we still have to add to make the predicted probabilities correspond to the observed ones?</li>
</ul>
</li>
<li>
<span class="math inline">\(\alpha_c\)</span>:
<ul>
<li>
<span class="math inline">\(&gt; 0\)</span>: <span class="math inline">\({}_{*} \widehat{\pi}_i\)</span> is too low on average and hence, on average the risks are underestimated. You have to increase it to make it correspond to the observed probabilities.</li>
<li>
<span class="math inline">\(&lt; 0\)</span>: <span class="math inline">\({}_{*} \widehat{\pi}_i\)</span> is too high on average and hence, on average the risks are overestimated. You have to decrease it to make it correspond to the observed probabilities.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3" number="4.2">
<h3 id="i-have-predicted-probabilities-of-0-or-1--why-is-this-not-allowed-by-default-and-why-do-i-get-these-annoying-warning-messages">
<span class="header-section-number">4.2</span> I have predicted probabilities of 0 or 1. Why is this not allowed by default and why do I get these annoying warning messages?<a class="anchor" aria-label="anchor" href="#i-have-predicted-probabilities-of-0-or-1--why-is-this-not-allowed-by-default-and-why-do-i-get-these-annoying-warning-messages"></a>
</h3>
<p>Predicted probabilities of 0 or 1 imply that there is no more randomness and that the process is deterministic. If the process was truly deterministic, we would not have to model it. Mostly the presence of perfect predictions signifies that something went wrong when fitting the model or that the model is severely overfitted. We therefore make sure that this is not allowed by default and delete these observations. We observe this behavior in the following cases:
<br> - logistic regression: with quasi-complete separation, the coefficients tend to infinity;
<br> - tree-based methods: one of the leaf nodes contains only observations with either 0 or 1;
<br> - neural networks: the weights tend to infinity and this is known as weight/gradient explosion.</p>
<p>If you are confident that nothing is wrong with the model fit, then you can obtain a calibration curve by setting the argument <code>allowPerfectPredictions</code> to <code>TRUE</code>. In this case, predictions of 0 and 1 are replaced by values 1e-8 and 1 - 1e-8, respectively. Do take this into account when interpreting the performance measures, as these are not calculated with the original values.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">yTest</span> <span class="op">=</span> <span class="va">testdata</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">pHat</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">pHat</span><span class="op">)</span>, <span class="fl">5</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="../reference/val.prob.ci.2.html">val.prob.ci.2</a></span><span class="op">(</span><span class="va">pHat</span>, <span class="va">yTest</span>, allowPerfectPredictions <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in val.prob.ci.2(pHat, yTest, allowPerfectPredictions = TRUE): There are predictions with value 0 or 1! These are replaced by values 1e-8 and 1 - 1e-8, respectively. Take this into account when interpreting the performance measures, as these are not calculated with the original values.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Please check your model, as this may be an indication of overfitting. Predictions of 0 or 1 imply that these predicted values are deterministic.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; We observe this in the following cases:</span></span>
<span><span class="co">#&gt;  - logistic regression: with quasi-complete separation, the coefficients tend to infinity;</span></span>
<span><span class="co">#&gt;  - tree-based methods: one of the leaf nodes contains only observations with either 0 or 1;</span></span>
<span><span class="co">#&gt;  - neural networks: the weights tend to infinity and this is known as weight/gradient explosion.</span></span></code></pre></div>
<p><img src="CalibrationCurves_files/figure-html/unnamed-chunk-26-1.png" width="100%"></p>
</div>
</div>
<div class="section level2" number="5">
<h2 id="references">
<span class="header-section-number">5</span> References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Alba2017" class="csl-entry">
Alba, Ana Carolina, Thomas Agoritsas, Michael Walsh, Steven Hanna, Alfonso Iorio, P. J Devereaux, Thomas McGinn, and Gordon Guyatt. 2017. <span>“<span class="nocase">Discrimination and Calibration of Clinical Prediction Models: Users’ Guides to the Medical Literature</span>.”</span> <em>JAMA : The Journal of the American Medical Association</em> 318 (14): 1377–84.
</div>
<div id="ref-Campo2023GCF" class="csl-entry">
De Cock Campo, Bavo. 2023. <span>“Towards Reliable Predictive Analytics: A Generalized Calibration Framework.”</span> <a href="https://arxiv.org/abs/2309.08559" class="external-link">https://arxiv.org/abs/2309.08559</a>.
</div>
<div id="ref-ClinicalPredictionModels" class="csl-entry">
Steyerberg, Ewout W. 2019. <em>Clinical Prediction Models: A Practical Approach to Development, Validation, and Updating</em>. Statistics for Biology and Health. Cham: Springer International Publishing AG.
</div>
<div id="ref-VanCalster2019" class="csl-entry">
Van Calster, Ben, David J McLernon, Maarten van Smeden, Laure Wynants, Ewout W Steyerberg, Patrick Bossuyt, Gary S Collins, Petra MacAskill, Karel G. M Moons, and Anew J Vickers. 2019. <span>“Calibration: The Achilles Heel of Predictive Analytics.”</span> <em>BMC Medicine</em> 17 (1): 230–30.
</div>
<div id="ref-VanCalster2016" class="csl-entry">
Van Calster, Ben, Daan Nieboer, Yvonne Vergouwe, Bavo De Cock, Michael J Pencina, and Ewout W Steyerberg. 2016. <span>“A Calibration Hierarchy for Risk Models Was Defined: From Utopia to Empirical Data.”</span> <em>Journal of Clinical Epidemiology</em> 74: 167–76.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Bavo De Cock Campo.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
