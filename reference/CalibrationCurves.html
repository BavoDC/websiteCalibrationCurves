<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Using this package, you can assess the calibration performance of your prediction model. That is, to which extent the predictions and correspond with what we observe empirically.
 To assess the calibration of model with a binary outcome, you can use the val.prob.ci.2 or the valProbggplot function. If the outcome of your prediction model
 is not binary but follows a different distribution of the exponential family, you can employ the genCalCurve function.
If you are not familiar with the theory and/or application of calibration, you can consult the vignette of the package. This vignette provides a comprehensive overview of the theory and
 contains a tutorial with some practical examples. Further, we suggest the reader to consult the paper on generalized calibration curves on arXiv.
 In this paper, we provide the theoretical background on the generalized calibration framework and illustrate its applicability with some prototypical examples of both statistical and
 machine learning prediction models that are well-calibrated, overfit and underfit.
Originally, the package only contained functions to assess the calibration of prediction models with a binary outcome. The details section provides some background information on the
 history of the package's development."><title>General information on the package and its functions — CalibrationCurves • CalibrationCurves</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="General information on the package and its functions — CalibrationCurves"><meta property="og:description" content="Using this package, you can assess the calibration performance of your prediction model. That is, to which extent the predictions and correspond with what we observe empirically.
 To assess the calibration of model with a binary outcome, you can use the val.prob.ci.2 or the valProbggplot function. If the outcome of your prediction model
 is not binary but follows a different distribution of the exponential family, you can employ the genCalCurve function.
If you are not familiar with the theory and/or application of calibration, you can consult the vignette of the package. This vignette provides a comprehensive overview of the theory and
 contains a tutorial with some practical examples. Further, we suggest the reader to consult the paper on generalized calibration curves on arXiv.
 In this paper, we provide the theoretical background on the generalized calibration framework and illustrate its applicability with some prototypical examples of both statistical and
 machine learning prediction models that are well-calibrated, overfit and underfit.
Originally, the package only contained functions to assess the calibration of prediction models with a binary outcome. The details section provides some background information on the
 history of the package's development."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">CalibrationCurves</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.6</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../articles/CalibrationCurves.html">Get started</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"></ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>General information on the package and its functions</h1>
      
      <div class="d-none name"><code>CalibrationCurves.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Using this package, you can assess the calibration performance of your prediction model. That is, to which extent the predictions and correspond with what we observe empirically.
 To assess the calibration of model with a binary outcome, you can use the <code><a href="val.prob.ci.2.html">val.prob.ci.2</a></code> or the <code><a href="valProbggplot.html">valProbggplot</a></code> function. If the outcome of your prediction model
 is not binary but follows a different distribution of the exponential family, you can employ the <code><a href="genCalCurve.html">genCalCurve</a></code> function.</p>
<p>If you are not familiar with the theory and/or application of calibration, you can consult the vignette of the package. This vignette provides a comprehensive overview of the theory and
 contains a tutorial with some practical examples. Further, we suggest the reader to consult the <a href="https://arxiv.org/abs/2309.08559" class="external-link">paper</a> on generalized calibration curves on arXiv.
 In this paper, we provide the theoretical background on the generalized calibration framework and illustrate its applicability with some prototypical examples of both statistical and
 machine learning prediction models that are well-calibrated, overfit and underfit.</p>
<p>Originally, the package only contained functions to assess the calibration of prediction models with a binary outcome. The details section provides some background information on the
 history of the package's development.</p>
    </div>


    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Some years ago, Yvonne Vergouwe and Ewout Steyerberg adapted the function <code><a href="https://rdrr.io/pkg/rms/man/val.prob.html" class="external-link">val.prob</a></code> from the rms-package (<a href="https://cran.r-project.org/package=rms" class="external-link">https://cran.r-project.org/package=rms</a>) into <code>val.prob.ci</code> and added the following functions to <code><a href="https://rdrr.io/pkg/rms/man/val.prob.html" class="external-link">val.prob</a></code>:</p>
<ul><li><p>Scaled Brier score by relating to max for average calibrated Null model</p></li>
<li><p>Risk distribution according to outcome</p></li>
<li><p>0 and 1 to indicate outcome label; set with <code>d1lab=".."</code>, <code>d0lab=".."</code></p></li>
<li><p>Labels: y axis: "Observed Frequency"; Triangle: "Grouped observations"</p></li>
<li><p>Confidence intervals around triangles</p></li>
<li><p>A cut-off can be plotted; set x coordinate</p></li>
</ul><p>In December 2015, Bavo De Cock, Daan Nieboer, and Ben Van Calster adapted
this to <code><a href="val.prob.ci.2.html">val.prob.ci.2</a></code>:</p><ul><li><p>Flexible calibration curves can be obtained using loess (default) or
    restricted cubic splines, with pointwise 95% confidence intervals. Flexible calibration curves are now given by default and this decision is based on the findings reported in Van Calster et al. (2016).</p></li>
<li><p>Loess: confidence intervals can be obtained in closed form or using bootstrapping
    (CL.BT=T will do bootstrapping with 2000 bootstrap samples, however
    this will take a while)</p></li>
<li><p>RCS: 3 to 5 knots can be used</p><ul><li><p>the knot locations will be estimated using default quantiles of
         x (by <code><a href="https://rdrr.io/pkg/Hmisc/man/rcspline.eval.html" class="external-link">rcspline.eval</a></code>, see <code><a href="https://rdrr.io/pkg/Hmisc/man/rcspline.plot.html" class="external-link">rcspline.plot</a></code> and <code><a href="https://rdrr.io/pkg/Hmisc/man/rcspline.eval.html" class="external-link">rcspline.eval</a></code>)</p></li>
<li><p>if estimation problems occur at the specified number of knots
         (nr.knots, default is 5), the analysis is repeated with
          nr.knots-1 until the problem has disappeared and the function stops if there is still an estimation problem with 3 knots</p></li>
</ul></li>
<li><p>You can now adjust the plot through use of normal plot commands
    (<code>cex.axis</code> etcetera), and the size of the legend now has to be specified in
    <code>cex.leg</code></p></li>
<li><p>Label y-axis: "Observed proportion"</p></li>
<li><p>Stats: added the Estimated Calibration Index (ECI), a statistical
    measure to quantify lack of calibration (Van Hoorde et al., 2015)</p></li>
<li><p>Stats to be shown in the plot: by default we show the <code>"abc"</code> of model performance (Steyerberg et al., 2011). That is, calibration intercept (calibration-in-the-large), calibration slope and c-
    statistic. Alternatively, the user can select the statistics of
    choice (e.g. <code>dostats=c("C (ROC)","R2")</code> or <code>dostats=c(2,3)</code>.</p></li>
<li><p>Vectors p, y and logit no longer have to be sorted</p></li>
</ul><p>In 2023, Bavo De Cock (Campo) published a <a href="https://arxiv.org/abs/2309.08559" class="external-link">paper</a> that introduces the generalized calibration framework. This framework is an extension of the logistic calibration framework to prediction models where the outcome's distribution is a member of the exponential family. As such, we are able to assess the calibration of a wider range of prediction models. The methods in this paper are implemented
in the CalibrationCurves package.</p>

<p>The most current version of this package can always be found on
<a href="https://github.com/BavoDC" class="external-link">https://github.com/BavoDC</a> and can easily be installed using the following code: <br><code>install.packages("devtools") # if not yet installed</code> <br><code><a href="https://devtools.r-lib.org/" class="external-link">require(devtools)</a></code> <br><code>install_github("BavoDC/CalibrationCurves", dependencies = TRUE, build_vignettes = TRUE)</code> <br></p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>De Cock Campo, B. (2023). Towards reliable predictive analytics: a generalized calibration framework. arXiv:2309.08559, available at <a href="https://arxiv.org/abs/2309.08559" class="external-link">https://arxiv.org/abs/2309.08559</a>.</p>
<p>Steyerberg, E.W.Van Calster, B., Pencina, M.J. (2011). Performance measures for prediction models and markers : evaluation of predictions and classifications. <em>Revista Espanola de Cardiologia</em>, <b>64(9)</b>, pp. 788-794</p>
<p>Van Calster, B., Nieboer, D., Vergouwe, Y., De Cock, B., Pencina M., Steyerberg E.W. (2016). A calibration hierarchy for risk models was defined: from utopia to empirical data. <em>Journal of Clinical Epidemiology</em>, <b>74</b>, pp. 167-176</p>
<p>Van Hoorde, K., Van Huffel, S., Timmerman, D., Bourne, T., Van Calster, B. (2015).
A spline-based tool to assess and visualize the calibration of multiclass risk predictions.
<em>Journal of Biomedical Informatics</em>, <b>54</b>, pp. 283-93</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Bavo De Cock Campo.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer></div>

  

  

  </body></html>

